{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Deep_Smote.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Inicializações, mkdir"
      ],
      "metadata": {
        "id": "plbr3BQD988Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4FAU1Rv3WjS9"
      },
      "outputs": [],
      "source": [
        "#!pip install torch==1.2.0+cu92 torchvision==0.4.0+cu92 -f https://download.pytorch.org/whl/torch_stable.html"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "!mkdir -p MNIST/trn_img/\n",
        "!mkdir -p MNIST/trn_lab/\n",
        "!mkdir -p MNIST/models/crs5/0/\n",
        "!mkdir -p MNIST/models/crs5/1/\n",
        "!mkdir -p MNIST/models/crs5/2/\n",
        "!mkdir -p MNIST/models/crs5/3/\n",
        "!mkdir -p MNIST/models/crs5/4/\n",
        "!mkdir -p MNIST/trn_img_f/\n",
        "!mkdir -p MNIST/trn_lab_f/\n",
        "\n",
        "!mkdir FashionMNIST/trn_img/\n",
        "!mkdir FashionMNIST/trn_lab/\n",
        "!mkdir -p FashionMNIST/models/crs5/0/\n",
        "!mkdir -p FashionMNIST/models/crs5/1/\n",
        "!mkdir -p FashionMNIST/models/crs5/2/\n",
        "!mkdir -p FashionMNIST/models/crs5/3/\n",
        "!mkdir -p FashionMNIST/models/crs5/4/\n",
        "!mkdir -p FashionMNIST/trn_img_f/\n",
        "!mkdir -p FashionMNIST/trn_lab_f/\n",
        "\n",
        "!mkdir CIFAR10/trn_img/\n",
        "!mkdir CIFAR10/trn_lab/\n",
        "!mkdir -p CIFAR10/models/crs5/0/\n",
        "!mkdir -p CIFAR10/models/crs5/1/\n",
        "!mkdir -p CIFAR10/models/crs5/2/\n",
        "!mkdir -p CIFAR10/models/crs5/3/\n",
        "!mkdir -p CIFAR10/models/crs5/4/\n",
        "!mkdir -p CIFAR10/trn_img_f/\n",
        "!mkdir -p CIFAR10/trn_lab_f/\n",
        "\n",
        "!mkdir SVHN/trn_img/\n",
        "!mkdir SVHN/trn_lab/\n",
        "!mkdir -p SVHN/models/crs5/0//models/crs5/0/\n",
        "!mkdir -p SVHN/models/crs5/1//models/crs5/1/\n",
        "!mkdir -p SVHN/models/crs5/2//models/crs5/2/\n",
        "!mkdir -p SVHN/models/crs5/3//models/crs5/3/\n",
        "!mkdir -p SVHN/models/crs5/4//models/crs5/4/\n",
        "!mkdir -p SVHN/trn_img_f/\n",
        "!mkdir -p SVHN/trn_lab_f/\n",
        "\n",
        "\n",
        "!mkdir CelebA/trn_img/\n",
        "!mkdir CelebA/trn_lab/\n",
        "!mkdir -p CelebA/models/crs5/0//models/crs5/0/\n",
        "!mkdir -p CelebA/models/crs5/1//models/crs5/1/\n",
        "!mkdir -p CelebA/models/crs5/2//models/crs5/2/\n",
        "!mkdir -p CelebA/models/crs5/3//models/crs5/3/\n",
        "!mkdir -p CelebA/models/crs5/4//models/crs5/4/\n",
        "!mkdir -p CelebA/trn_img_f/\n",
        "!mkdir -p CelebA/trn_lab_f/\n"
      ],
      "metadata": {
        "id": "G_eVvGkUVcPF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset\n",
        "import numpy as np\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import time\n",
        "import os\n",
        "from torchvision import datasets #Import MNIST from torchvision\n",
        "import torchvision.transforms as transforms\n",
        "print(torch.version.cuda) #10.1\n",
        "t3 = time.time()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPZ--wCV4y_X",
        "outputId": "4f6522dd-3c97-4ea4-f10e-04e50e7582e2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Argumentos"
      ],
      "metadata": {
        "id": "W9WH7FJWkX05"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##############################################################################\n",
        "\"\"\"args for AE\"\"\"\n",
        "\n",
        "#MNIST e FMNIST n_channel = 1 e n_z = 300\n",
        "#Cifar10 e SVHN n_channel = 3 e n_z = 600\n",
        "\n",
        "args = {}\n",
        "args['dim_h'] = 64         # factor controlling size of hidden layers\n",
        "args['n_channel'] = 1 #1  ou 3    # number of channels in the input data \n",
        "\n",
        "args['n_z'] = 300 #300 ou 600     # number of dimensions in latent space. \n",
        "\n",
        "args['sigma'] = 1.0        # variance in n_z\n",
        "args['lambda'] = 0.01      # hyper param for weight of discriminator loss\n",
        "args['lr'] = 0.0002        # learning rate for Adam optimizer .000\n",
        "args['epochs'] = 10       # how many epochs to run for\n",
        "args['batch_size'] = 100   # batch size for SGD\n",
        "args['save'] = True        # save weights at each epoch of training if True\n",
        "args['train'] = True       # train networks if True, else load networks from\n",
        "\n",
        "args['dataset'] = 'mnist' # 'mnist' ou 'fashionmnist' ou 'cifar10' ou 'svhn'  # specify which dataset to use\n",
        "\n"
      ],
      "metadata": {
        "id": "w3fvtoUo48SS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importando os datasets "
      ],
      "metadata": {
        "id": "epukq3tXNmzH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###############################################################################\n",
        "\n",
        "\n",
        "#NOTE: Download the training ('.../0_trn_img.txt') and label files \n",
        "# ('.../0_trn_lab.txt').  Place the files in directories (e.g., ../MNIST/trn_img/\n",
        "# and /MNIST/trn_lab/).  Originally, when the code was written, it was for 5 fold\n",
        "#cross validation and hence there were 5 files in each of the \n",
        "#directories.  Here, for illustration, we use only 1 training and 1 label\n",
        "#file (e.g., '.../0_trn_img.txt' and '.../0_trn_lab.txt').\n",
        "\n",
        "## transformation\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if( args['dataset']== 'mnist'):\n",
        "  transform = transforms.Compose([transforms.ToTensor(), transforms.Resize(size=(28,28))])\n",
        "  dataset_torch = datasets.MNIST(root='./', train=True, download=True, transform=transform)\n",
        "  dir_model = 'MNIST'\n",
        "  print(\"Mnist\")\n",
        "elif( args['dataset']== 'fashionmnist'):\n",
        "  transform = transforms.Compose([transforms.ToTensor(), transforms.Resize(size=(28,28))])\n",
        "  dataset_torch = datasets.FashionMNIST(root='./', train=True, download=True, transform=transform)\n",
        "  dir_model = 'FashionMNIST'\n",
        "  print(\"FashionMNIST\")\n",
        "elif( args['dataset']== 'cifar10'):\n",
        "  transform = transforms.Compose( [transforms.ToTensor(), transforms.Resize(size=(32,32))])\n",
        "  dataset_torch = datasets.CIFAR10(root='./', train=True, download=True, transform=transform)\n",
        "  dir_model = 'CIFAR10'\n",
        "  print(\"CIFAR10\")\n",
        "elif( args['dataset']== 'svhn'):\n",
        "  transform = transforms.Compose( [transforms.ToTensor(), transforms.Resize(size=(32,32))])\n",
        "  dataset_torch = datasets.SVHN(root='./', train=True, download=True, transform=transform)\n",
        "  dir_model = 'SVHN'\n",
        "  print(\"SVHN\")\n",
        "\n",
        "\n",
        "'''\n",
        "\n",
        "!mv MNIST/raw/train-images-idx3-ubyte MNIST/trn_img/0_trn_img.txt\n",
        "!mv MNIST/raw/train-labels-idx1-ubyte MNIST/trn_lab/0_trn_lab.txt\n",
        "dtrnimg = 'MNIST/trn_img/'\n",
        "dtrnlab = 'MNIST/trn_lab/'\n",
        "\n",
        "## download and load training dataset\n",
        "#trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,\n",
        "#                                          shuffle=True, num_workers=2)\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "-dQSVlGI5NxM",
        "outputId": "a8006876-74c0-41ed-80d7-4ca072399b09"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mnist\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n\\n!mv MNIST/raw/train-images-idx3-ubyte MNIST/trn_img/0_trn_img.txt\\n!mv MNIST/raw/train-labels-idx1-ubyte MNIST/trn_lab/0_trn_lab.txt\\ndtrnimg = 'MNIST/trn_img/'\\ndtrnlab = 'MNIST/trn_lab/'\\n\\n## download and load training dataset\\n#trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,\\n#                                          shuffle=True, num_workers=2)\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IELUThNSFJuG",
        "outputId": "77352200-8328-4aee-d7c4-a68289f20343"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: ./\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: Compose(\n",
              "               ToTensor()\n",
              "               Resize(size=(28, 28), interpolation=bilinear, max_size=None, antialias=None)\n",
              "           )"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classes Encoder e Decoder "
      ],
      "metadata": {
        "id": "j8ciHDDY4-LZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "tx4_Xe2nOzJ_"
      },
      "outputs": [],
      "source": [
        "##############################################################################\n",
        "\n",
        "\n",
        "## create encoder model and decoder model\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.n_channel = args['n_channel']\n",
        "        self.dim_h = args['dim_h']\n",
        "        self.n_z = args['n_z']\n",
        "        \n",
        "        # convolutional filters, work excellent with image data\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(self.n_channel, self.dim_h, 4, 2, 1, bias=False),\n",
        "            #nn.ReLU(True),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(self.dim_h, self.dim_h * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(self.dim_h * 2),\n",
        "            #nn.ReLU(True),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(self.dim_h * 2, self.dim_h * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(self.dim_h * 4),\n",
        "            #nn.ReLU(True),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            \n",
        "            \n",
        "            nn.Conv2d(self.dim_h * 4, self.dim_h * 8, 4, 2, 1, bias=False),\n",
        "            \n",
        "            #3d and 32 by 32\n",
        "            #nn.Conv2d(self.dim_h * 4, self.dim_h * 8, 4, 1, 0, bias=False),\n",
        "            \n",
        "            nn.BatchNorm2d(self.dim_h * 8), # 40 X 8 = 320\n",
        "            #nn.ReLU(True),\n",
        "            nn.LeakyReLU(0.2, inplace=True) )#,\n",
        "            #nn.Conv2d(self.dim_h * 8, 1, 2, 1, 0, bias=False))\n",
        "            #nn.Conv2d(self.dim_h * 8, 1, 4, 1, 0, bias=False))\n",
        "        # final layer is fully connected\n",
        "        self.fc = nn.Linear(self.dim_h * (2 ** 3), self.n_z)\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        #print('enc')\n",
        "        #print('input ',x.size()) #torch.Size([100, 3,32,32])\n",
        "        x = self.conv(x)\n",
        "        \n",
        "        x = x.squeeze()\n",
        "        #print('aft squeeze ',x.size()) #torch.Size([128, 320])\n",
        "        #aft squeeze  torch.Size([100, 320])\n",
        "        x = self.fc(x)\n",
        "        #print('out ',x.size()) #torch.Size([128, 20])\n",
        "        #out  torch.Size([100, 300])\n",
        "        return x\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.n_channel = args['n_channel']\n",
        "        self.dim_h = args['dim_h']\n",
        "        self.n_z = args['n_z']\n",
        "\n",
        "        # first layer is fully connected\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(self.n_z, self.dim_h * 8 * 7 * 7),\n",
        "            nn.ReLU())\n",
        "\n",
        "        # deconvolutional filters, essentially inverse of convolutional filters\n",
        "        self.deconv = nn.Sequential(\n",
        "            nn.ConvTranspose2d(self.dim_h * 8, self.dim_h * 4, 4),\n",
        "            nn.BatchNorm2d(self.dim_h * 4),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(self.dim_h * 4, self.dim_h * 2, 4),\n",
        "            nn.BatchNorm2d(self.dim_h * 2),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(self.dim_h * 2, 1, 4, stride=2),\n",
        "            #nn.Sigmoid())\n",
        "            nn.Tanh())\n",
        "\n",
        "    def forward(self, x):\n",
        "        #print('dec')\n",
        "        #print('input ',x.size())\n",
        "        x = self.fc(x)\n",
        "        x = x.view(-1, self.dim_h * 8, 7, 7)\n",
        "        x = self.deconv(x)\n",
        "        return x\n",
        "\n",
        "##############################################################################\n",
        "\"\"\"set models, loss functions\"\"\"\n",
        "# control which parameters are frozen / free for optimization\n",
        "def free_params(module: nn.Module):\n",
        "    for p in module.parameters():\n",
        "        p.requires_grad = True\n",
        "\n",
        "def frozen_params(module: nn.Module):\n",
        "    for p in module.parameters():\n",
        "        p.requires_grad = False\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SMOTE (Do código de treinamento, não do generate samples) \n"
      ],
      "metadata": {
        "id": "frCahvBy5Rv3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "##############################################################################\n",
        "\"\"\"functions to create SMOTE images\"\"\"\n",
        "\n",
        "def biased_get_class(c):\n",
        "    \n",
        "    xbeg = dec_x[dec_y == c]\n",
        "    ybeg = dec_y[dec_y == c]\n",
        "    \n",
        "    return xbeg, ybeg\n",
        "    #return xclass, yclass\n",
        "\n",
        "\n",
        "def G_SM(X, y,n_to_sample,cl):\n",
        "\n",
        "    # determining the number of samples to generate\n",
        "    #n_to_sample = 10 \n",
        "\n",
        "    # fitting the model\n",
        "    n_neigh = 5 + 1\n",
        "    nn = NearestNeighbors(n_neighbors=n_neigh, n_jobs=1)\n",
        "    nn.fit(X)\n",
        "    dist, ind = nn.kneighbors(X)\n",
        "\n",
        "    # generating samples\n",
        "    base_indices = np.random.choice(list(range(len(X))),n_to_sample)\n",
        "    neighbor_indices = np.random.choice(list(range(1, n_neigh)),n_to_sample)\n",
        "\n",
        "    X_base = X[base_indices]\n",
        "    X_neighbor = X[ind[base_indices, neighbor_indices]]\n",
        "\n",
        "    samples = X_base + np.multiply(np.random.rand(n_to_sample,1),\n",
        "            X_neighbor - X_base)\n",
        "\n",
        "    #use 10 as label because 0 to 9 real classes and 1 fake/smoted = 10\n",
        "    return samples, [cl]*n_to_sample\n",
        "\n",
        "#xsamp, ysamp = SM(xclass,yclass)\n",
        "'''"
      ],
      "metadata": {
        "id": "BFaOP0oD5RIO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "a95b26e0-431e-4f8a-f40e-33bb57355757"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n##############################################################################\\n\"\"\"functions to create SMOTE images\"\"\"\\n\\ndef biased_get_class(c):\\n    \\n    xbeg = dec_x[dec_y == c]\\n    ybeg = dec_y[dec_y == c]\\n    \\n    return xbeg, ybeg\\n    #return xclass, yclass\\n\\n\\ndef G_SM(X, y,n_to_sample,cl):\\n\\n    # determining the number of samples to generate\\n    #n_to_sample = 10 \\n\\n    # fitting the model\\n    n_neigh = 5 + 1\\n    nn = NearestNeighbors(n_neighbors=n_neigh, n_jobs=1)\\n    nn.fit(X)\\n    dist, ind = nn.kneighbors(X)\\n\\n    # generating samples\\n    base_indices = np.random.choice(list(range(len(X))),n_to_sample)\\n    neighbor_indices = np.random.choice(list(range(1, n_neigh)),n_to_sample)\\n\\n    X_base = X[base_indices]\\n    X_neighbor = X[ind[base_indices, neighbor_indices]]\\n\\n    samples = X_base + np.multiply(np.random.rand(n_to_sample,1),\\n            X_neighbor - X_base)\\n\\n    #use 10 as label because 0 to 9 real classes and 1 fake/smoted = 10\\n    return samples, [cl]*n_to_sample\\n\\n#xsamp, ysamp = SM(xclass,yclass)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Treinamento do Encoder/Decoder - Main"
      ],
      "metadata": {
        "id": "clBS35Az5a-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#%%time\n",
        "'''\n",
        "ids = os.listdir(dtrnimg)\n",
        "idtri_f = [os.path.join(dtrnimg, image_id) for image_id in ids]\n",
        "print(idtri_f)\n",
        "\n",
        "ids = os.listdir(dtrnlab)\n",
        "idtrl_f = [os.path.join(dtrnlab, image_id) for image_id in ids]\n",
        "print(idtrl_f)\n",
        "'''\n",
        "\n",
        "for i in range(1):\n",
        "#for i in range(len(ids)):\n",
        "    print()\n",
        "    print(i)\n",
        "    encoder = Encoder(args)\n",
        "    decoder = Decoder(args)\n",
        "\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    print(device)\n",
        "    decoder = decoder.to(device)\n",
        "    encoder = encoder.to(device)\n",
        "\n",
        "    train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "    #decoder loss function\n",
        "    criterion = nn.MSELoss()\n",
        "    criterion = criterion.to(device)\n",
        "    \n",
        "#    trnimgfile = idtri_f[i]\n",
        "#    trnlabfile = idtrl_f[i]\n",
        "    \n",
        "#    print(trnimgfile)\n",
        "#    print(trnlabfile)\n",
        "#    dec_x = trnimgfile\n",
        "#    dec_y = trnlabfile\n",
        "\n",
        "#    dec_x = \n",
        "#    dec_y = MNISTtorch.targets\n",
        "#   print('train imgs before reshape ',dec_x.shape) \n",
        "#   print('train labels ',dec_y.shape) \n",
        "#   print(collections.Counter(dec_y))\n",
        "#   dec_x = dec_x.reshape(dec_x.shape[0],1,28,28)   \n",
        "#   print('train imgs after reshape ',dec_x.shape) \n",
        "\n",
        "    dl_batch_size = batch_size=dataset_torch.__len__()\n",
        "    batch_size = args['batch_size']\n",
        "    num_workers = 0\n",
        "\n",
        "    #torch.Tensor returns float so if want long then use torch.tensor\n",
        " #   tensor_x = dec_x\n",
        " #   tensor_y = MNISTtorch.target\n",
        " #   mnist_bal = TensorDataset(tensor_x,tensor_y) \n",
        "    train_loader = torch.utils.data.DataLoader(dataset_torch, batch_size=batch_size,shuffle=True,num_workers=num_workers)\n",
        "    \n",
        "    ## Carregar dataset na memória\n",
        "    dl_aux = torch.utils.data.DataLoader(dataset_torch, batch_size=dl_batch_size,shuffle=True,num_workers=num_workers)\n",
        "    \n",
        "    dec_x, dec_y = next(iter(dl_aux))\n",
        "\n",
        "    del dl_aux\n",
        "\n",
        "    classes = (0, 1, 2, 3, 4, 5, 6, 7, 8, 9)\n",
        "\n",
        "    best_loss = np.inf\n",
        "\n",
        "    t0 = time.time()\n",
        "    if args['train']:\n",
        "        enc_optim = torch.optim.Adam(encoder.parameters(), lr = args['lr'])\n",
        "        dec_optim = torch.optim.Adam(decoder.parameters(), lr = args['lr'])\n",
        "    \n",
        "        for epoch in range(args['epochs']):\n",
        "            train_loss = 0.0\n",
        "            tmse_loss = 0.0\n",
        "            tdiscr_loss = 0.0\n",
        "            # train for one epoch -- set nets to train mode\n",
        "            encoder.train()\n",
        "            decoder.train()\n",
        "        \n",
        "            for images,labs in train_loader:\n",
        "            \n",
        "                # zero gradients for each batch\n",
        "                encoder.zero_grad()\n",
        "                decoder.zero_grad()\n",
        "                #print(images)\n",
        "                images, labs = images.to(device), labs.to(device)\n",
        "                #print('images ',images.size()) \n",
        "                labsn = labs.detach().cpu().numpy()\n",
        "                #print('labsn ',labsn.shape, labsn)\n",
        "            \n",
        "                # run images\n",
        "                z_hat = encoder(images)\n",
        "            \n",
        "                x_hat = decoder(z_hat) #decoder outputs tanh\n",
        "                #print('xhat ', x_hat.size())\n",
        "                #print(x_hat)\n",
        "\n",
        "                #Reconstruction Loss\n",
        "                mse = criterion(x_hat,images)\n",
        "                #print('mse ',mse)\n",
        "                \n",
        "                       \n",
        "                resx = []\n",
        "                resy = []\n",
        "\n",
        "                #Randomly sample classes            \n",
        "                tc = np.random.randint(10)\n",
        "                #tc = 9\n",
        "                #print(\"Class:\", tc)\n",
        "\n",
        "                #Randomly sample nsamp instances of that class\n",
        "                xbeg = dec_x[dec_y == tc]\n",
        "                ybeg = dec_y[dec_y == tc] \n",
        "                xlen = len(xbeg)\n",
        "                #print(\"xlen\", xlen)\n",
        "                nsamp = min(xlen, 100)\n",
        "                ind = np.random.choice(list(range(len(xbeg))),nsamp,replace=False)\n",
        "                xclass = xbeg[ind]\n",
        "                yclass = ybeg[ind]\n",
        "            \n",
        "                xclen = len(xclass)\n",
        "                #print('xclen ',xclen)\n",
        "                xcminus = np.arange(1,xclen)\n",
        "                #print('minus ',xcminus.shape,xcminus)\n",
        "                \n",
        "                xcplus = np.append(xcminus,0)\n",
        "                #print('xcplus ',xcplus)\n",
        "                xcnew = (xclass[[xcplus],:])\n",
        "                #xcnew = np.squeeze(xcnew)\n",
        "                xcnew = xcnew.reshape(xcnew.shape[1],xcnew.shape[2],xcnew.shape[3],xcnew.shape[4])\n",
        "                #print('xcnew ',xcnew.shape)\n",
        "            \n",
        "                xcnew = torch.Tensor(xcnew)\n",
        "                xcnew = xcnew.to(device)\n",
        "            \n",
        "                #Encode xclass to feature space\n",
        "                xclass = torch.Tensor(xclass)\n",
        "                xclass = xclass.to(device)\n",
        "                xclass = encoder(xclass)\n",
        "                #print('xclass ',xclass.shape) \n",
        "            \n",
        "                xclass = xclass.detach().cpu().numpy()\n",
        "            \n",
        "                xc_enc = (xclass[[xcplus],:])\n",
        "                xc_enc = np.squeeze(xc_enc)\n",
        "                #print('xc enc ',xc_enc.shape)\n",
        "            \n",
        "                xc_enc = torch.Tensor(xc_enc)\n",
        "                xc_enc = xc_enc.to(device)\n",
        "\n",
        "                #Decode\n",
        "                ximg = decoder(xc_enc)\n",
        "                \n",
        "                #Penalty Loss \n",
        "                mse2 = criterion(ximg,xcnew)\n",
        "            \n",
        "                comb_loss = mse2 + mse\n",
        "                comb_loss.backward()\n",
        "            \n",
        "                enc_optim.step()\n",
        "                dec_optim.step()\n",
        "            \n",
        "                train_loss += comb_loss.item()*images.size(0)\n",
        "                tmse_loss += mse.item()*images.size(0)\n",
        "                tdiscr_loss += mse2.item()*images.size(0)\n",
        "            \n",
        "                 \n",
        "            # print avg training statistics \n",
        "            train_loss = train_loss/len(train_loader)\n",
        "            tmse_loss = tmse_loss/len(train_loader)\n",
        "            tdiscr_loss = tdiscr_loss/len(train_loader)\n",
        "            print('Epoch: {} \\tTrain Loss: {:.6f} \\tmse loss: {:.6f} \\tmse2 loss: {:.6f}'.format(epoch,\n",
        "                    train_loss,tmse_loss,tdiscr_loss))\n",
        "            \n",
        "        \n",
        "#########################5 Way Cross Validation#################################       \n",
        "           #store the best encoder and decoder models\n",
        "            #here, /crs5 is a reference to 5 way cross validation, but is not\n",
        "            #necessary for illustration purposes\n",
        "            if train_loss < best_loss:\n",
        "                print('Saving..')\n",
        "                path_enc = dir_model+'/models/crs5/' \\\n",
        "                    + str(i) + '/bst_enc.pth'\n",
        "                path_dec = dir_model+'/models/crs5/' \\\n",
        "                    + str(i) + '/bst_dec.pth'\n",
        "             \n",
        "                torch.save(encoder.state_dict(), path_enc)\n",
        "                torch.save(decoder.state_dict(), path_dec)\n",
        "        \n",
        "                best_loss = train_loss\n",
        "################################################################################        \n",
        "        \n",
        "        #in addition, store the final model (may not be the best) for\n",
        "        #informational purposes\n",
        "        path_enc = dir_model+'/models/crs5/' \\\n",
        "            + str(i) + '/f_enc.pth'\n",
        "        path_dec = dir_model+'/models/crs5/' \\\n",
        "            + str(i) + '/f_dec.pth'\n",
        "        print(path_enc)\n",
        "        print(path_dec)\n",
        "        torch.save(encoder.state_dict(), path_enc)\n",
        "        torch.save(decoder.state_dict(), path_dec)\n",
        "        print()\n",
        "              \n",
        "    t1 = time.time()\n",
        "    print('total time(min): {:.2f}'.format((t1 - t0)/60))             \n",
        " \n",
        "t4 = time.time()\n",
        "print('final time(min): {:.2f}'.format((t4 - t3)/60))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDw9ow66lNS-",
        "outputId": "c12bd620-22a6-4438-89ee-1f62e043894d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0\n",
            "cuda\n",
            "Epoch: 0 \tTrain Loss: 6.737602 \tmse loss: 2.987084 \tmse2 loss: 3.750518\n",
            "Saving..\n",
            "Epoch: 1 \tTrain Loss: 1.803980 \tmse loss: 0.804419 \tmse2 loss: 0.999561\n",
            "Saving..\n",
            "Epoch: 2 \tTrain Loss: 1.231781 \tmse loss: 0.555022 \tmse2 loss: 0.676759\n",
            "Saving..\n",
            "Epoch: 3 \tTrain Loss: 0.972876 \tmse loss: 0.444046 \tmse2 loss: 0.528830\n",
            "Saving..\n",
            "Epoch: 4 \tTrain Loss: 0.811640 \tmse loss: 0.371826 \tmse2 loss: 0.439814\n",
            "Saving..\n",
            "Epoch: 5 \tTrain Loss: 0.700216 \tmse loss: 0.324581 \tmse2 loss: 0.375634\n",
            "Saving..\n",
            "Epoch: 6 \tTrain Loss: 0.633188 \tmse loss: 0.294065 \tmse2 loss: 0.339123\n",
            "Saving..\n",
            "Epoch: 7 \tTrain Loss: 0.569190 \tmse loss: 0.267565 \tmse2 loss: 0.301625\n",
            "Saving..\n",
            "Epoch: 8 \tTrain Loss: 0.533405 \tmse loss: 0.250202 \tmse2 loss: 0.283204\n",
            "Saving..\n",
            "Epoch: 9 \tTrain Loss: 0.498098 \tmse loss: 0.234496 \tmse2 loss: 0.263602\n",
            "Saving..\n",
            "MNIST/models/crs5/0/f_enc.pth\n",
            "MNIST/models/crs5/0/f_dec.pth\n",
            "\n",
            "total time(min): 8.87\n",
            "final time(min): 10.72\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Samples - SMOTE/Adasyn"
      ],
      "metadata": {
        "id": "HvCKOEQ6u9WU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6--G0g0SNsMq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##############################################################################\n",
        "\n",
        "def biased_get_class1(c):\n",
        "    \n",
        "    xbeg = dec_x[dec_y == c]\n",
        "    ybeg = dec_y[dec_y == c]\n",
        "    \n",
        "    return xbeg, ybeg\n",
        "    #return xclass, yclass\n",
        "'''\n",
        "\n",
        "def adasyn(X, y,  cl, m_major, m_minor, beta=1):\n",
        "  \n",
        "  Inputs:\n",
        "  X: xclasse, conjunto de dados da classe\n",
        "  y : yclasse, conjunto de labels da classe\n",
        "  cl : classe alvo\n",
        "  m_major : número de instâncias da classe majoritária\n",
        "  m_minor : número de instâncias da classe minoritária (alvo)\n",
        "  beta : parâmetros que controla quantas instâncias são geradas. Default=1\n",
        " \n",
        "  #Número de neighbors\n",
        "  K = 5\n",
        "  d= m_major/m_minor\n",
        "  #if(d>threshold) acaba aqui\n",
        "  G = (m_major-m_minor)*beta\n",
        "  # fitting the model\n",
        "\n",
        "\n",
        "  clf = neighbors.KNeighborsClassifier()\n",
        "  clf.fit(X, y)\n",
        "  Ri = []\n",
        "  Minority_per_xi = []\n",
        "  for i in range(m_minor):\n",
        "    # Returns indices of the closest neighbours, and return it as a list\n",
        "    xi = X[i, :].reshape(1, -1)\n",
        "    # Returns indices of the closest neighbours, and return it as a list\n",
        "    neighbours = clf.kneighbors(xi, n_neighbors=K, return_distance=False)[0]\n",
        "    delta=0\n",
        "    for j in range(len(neighbours)):\n",
        "      if(y[j]!=cl):\n",
        "        delta+=1\n",
        "    Ri.append(delta/K)\n",
        "    minority = []\n",
        "    for index in neighbours:\n",
        "            # Shifted back 1 because indices start at 0\n",
        "            if y[index]==cl :\n",
        "                minority.append(value)\n",
        "    Minority_per_xi.append(minority)\n",
        "  Ri_norm = []\n",
        "  for ri in Ri:\n",
        "    ri_norm = ri / sum(Ri)\n",
        "    Ri_norm.append(ri_norm)\n",
        "\n",
        "  assert (sum(Rhat_i) > 0.99)\n",
        "  Gi = []\n",
        "  for r in Ri_norm:\n",
        "    gi = round(r * G)\n",
        "    Gi.append(int(gi)) \n",
        "\n",
        "  for i in range(m_minor):\n",
        "    #gerar classes\n",
        "    neighbor_indices = np.random.choice(list(range(1, K+1)),Gi[i])\n",
        "    or j in range(Gi[i]):\n",
        "        # If the minority list is not empty\n",
        "        if Minority_per_xi[i]:\n",
        "            index = np.random.choice(Minority_per_xi[i])\n",
        "            xzi = X[index, :].reshape(1, -1)\n",
        "            si = xi + (xzi - xi) * np.random.uniform(0, 1)\n",
        "            syn_data.append(si)\n",
        "'''\n",
        "\n",
        "def G_SM1(X, y,n_to_sample,cl):\n",
        "\n",
        "    \n",
        "    # fitting the model\n",
        "    n_neigh = 5 + 1\n",
        "    knn = NearestNeighbors(n_neighbors=n_neigh, n_jobs=1)\n",
        "    knn.fit(X)\n",
        "    dist, ind = knn.kneighbors(X)\n",
        "\n",
        "    # generating samples\n",
        "    base_indices = np.random.choice(list(range(len(X))),n_to_sample)\n",
        "    neighbor_indices = np.random.choice(list(range(1, n_neigh)),n_to_sample)\n",
        "\n",
        "    X_base = X[base_indices]\n",
        "    X_neighbor = X[ind[base_indices, neighbor_indices]]\n",
        "\n",
        "    samples = X_base + np.multiply(np.random.rand(n_to_sample,1),\n",
        "            X_neighbor - X_base)\n",
        "\n",
        "    #use 10 as label because 0 to 9 real classes and 1 fake/smoted = 10\n",
        "    return samples, [cl]*n_to_sample\n",
        "\n",
        "#############################################################################\n",
        "\n"
      ],
      "metadata": {
        "id": "SAckSkq2w7OG"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir MNIST/trn_img_f/"
      ],
      "metadata": {
        "id": "jhDUfIcezIuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir MNIST/trn_lab_f/"
      ],
      "metadata": {
        "id": "BGQ84x1DzgJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "KVT9sLS1zSHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Samples - Main"
      ],
      "metadata": {
        "id": "u63YabLHNuXs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.printoptions(precision=5,suppress=True)\n",
        "#%time\n",
        "'''\n",
        "dtrnimg = '.../0_trn_img.txt'\n",
        "dtrnlab = '.../0_trn_lab.txt'\n",
        "\n",
        "ids = os.listdir(dtrnimg)\n",
        "idtri_f = [os.path.join(dtrnimg, image_id) for image_id in ids]\n",
        "print(idtri_f)\n",
        "\n",
        "ids = os.listdir(dtrnlab)\n",
        "idtrl_f = [os.path.join(dtrnlab, image_id) for image_id in ids]\n",
        "print(idtrl_f)\n",
        "'''\n",
        "#path on the computer where the models are stored\n",
        "modpth = './' +dir_model+'/models/crs5/'\n",
        "\n",
        "encf = []\n",
        "decf = []\n",
        "for p in range(5):\n",
        "    enc = modpth + '/' + str(p) + '/bst_enc.pth'\n",
        "    dec = modpth + '/' + str(p) + '/bst_dec.pth'\n",
        "    encf.append(enc)\n",
        "    decf.append(dec)\n",
        "    #print(enc)\n",
        "    #print(dec)\n",
        "    #print()\n",
        "\n",
        "for m in range(1):\n",
        "    print(m)\n",
        "    '''\n",
        "    trnimgfile = idtri_f[m]\n",
        "    trnlabfile = idtrl_f[m]\n",
        "    print(trnimgfile)\n",
        "    print(trnlabfile)\n",
        "    dec_x = np.loadtxt(trnimgfile) \n",
        "    dec_y = np.loadtxt(trnlabfile)\n",
        "\n",
        "    print('train imgs before reshape ',dec_x.shape) #(44993, 3072) 45500, 3072)\n",
        "    print('train labels ',dec_y.shape) #(44993,) (45500,)\n",
        "\n",
        "    dec_x = dec_x.reshape(dec_x.shape[0],1,28,28)\n",
        "\n",
        "    print('decy ',dec_y.shape)\n",
        "    print(collections.Counter(dec_y))\n",
        "    \n",
        "    print('train imgs after reshape ',dec_x.shape) #(45000,3,32,32)\n",
        "    '''\n",
        "    dl_batch_size = batch_size=dataset_torch.__len__()\n",
        "    batch_size = 128\n",
        "    num_workers = 0\n",
        "\n",
        "    #torch.Tensor returns float so if want long then use torch.tensor\n",
        " #   tensor_x = dec_x\n",
        " #   tensor_y = MNISTtorch.target\n",
        " #   mnist_bal = TensorDataset(tensor_x,tensor_y) \n",
        "    train_loader = torch.utils.data.DataLoader(dataset_torch, \n",
        "        batch_size=batch_size,shuffle=True,num_workers=num_workers)\n",
        "    \n",
        "    ## Carregar dataset na memória\n",
        "    dl_aux = torch.utils.data.DataLoader(dataset_torch, \n",
        "        batch_size=dl_batch_size,shuffle=True,num_workers=num_workers)\n",
        "    \n",
        "    dec_x, dec_y = next(iter(dl_aux))\n",
        "\n",
        "    del dl_aux\n",
        "\n",
        "    classes = (0, 1, 2, 3, 4, 5, 6, 7, 8, 9)\n",
        "\n",
        "    best_loss = np.inf\n",
        "\n",
        "    \n",
        "    #generate some images \n",
        "    train_on_gpu = torch.cuda.is_available()\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    \n",
        "    path_enc = encf[m]\n",
        "    path_dec = decf[m]\n",
        "\n",
        "    encoder = Encoder(args)\n",
        "    encoder.load_state_dict(torch.load(path_enc), strict=False)\n",
        "    encoder = encoder.to(device)\n",
        "\n",
        "    decoder = Decoder(args)\n",
        "    decoder.load_state_dict(torch.load(path_dec), strict=False)\n",
        "    decoder = decoder.to(device)\n",
        "\n",
        "    encoder.eval()\n",
        "    decoder.eval()\n",
        "\n",
        "    #imbal = [4500, 2000, 1000, 800, 600, 500, 400, 250, 150, 80]\n",
        "    if(args['dataset'] =='mnist' or args['dataset'] =='fashionmnist'):imbal = [4000, 2000, 1000, 750, 500, 350, 200, 100, 60, 40]\n",
        "\n",
        "    resx = []\n",
        "    resy = []\n",
        "    xclasses=[]\n",
        "    yclasses=[]\n",
        "    #Gerar um conjunto com todas as classes ordenadas\n",
        "    for i in range(0,10):\n",
        "      xclass, yclass = biased_get_class1(i)\n",
        "\n",
        "          \n",
        "      #encode xclass to feature space\n",
        "      xclass = torch.Tensor(xclass)\n",
        "      xclass = xclass.to(device)\n",
        "      xclass = encoder(xclass)\n",
        "\n",
        "          \n",
        "      xclass = xclass.detach().cpu().numpy()\n",
        "      xclasses.append(xclass)\n",
        "      yclasses.append(yclass)\n",
        "    \n",
        "    allClasses = np.concatenate(xclasses)\n",
        "    allY = np.concatenate(yclasses)\n",
        "\n",
        "    #Skipando a classe 1\n",
        "    for i in range(1,10):\n",
        "        xclass, yclass = xclasses[i], yclasses[i]\n",
        "        print(\"Len yclass\", len(yclass))\n",
        "        n = imbal[0] - imbal[i]\n",
        "        xsamp, ysamp = G_SM1(xclass,yclass,n,i)\n",
        "        print(len(ysamp))\n",
        "\n",
        "        ysamp = np.array(ysamp)\n",
        "\n",
        "    \n",
        "        \"\"\"to generate samples for resnet\"\"\"   \n",
        "        xsamp = torch.Tensor(xsamp)\n",
        "        xsamp = xsamp.to(device)\n",
        "        #xsamp = xsamp.view(xsamp.size()[0], xsamp.size()[1], 1, 1)\n",
        "        ximg = decoder(xsamp)\n",
        "\n",
        "        ximn = ximg.detach().cpu().numpy()\n",
        "        #ximn = np.expand_dims(ximn,axis=1)\n",
        "\n",
        "        resx.append(ximn)\n",
        "        resy.append(ysamp)\n",
        "\n",
        "    resx1 = np.vstack(resx)\n",
        "    resy1 = np.hstack(resy)\n",
        "\n",
        "    #resx1 = np.squeeze(resx1)\n",
        "\n",
        "\n",
        "    resx1 = resx1.reshape(resx1.shape[0],-1)\n",
        "\n",
        "    \n",
        "    dec_x1 = dec_x.reshape(dec_x.shape[0],-1)\n",
        "\n",
        "    combx = np.vstack((resx1,dec_x1))\n",
        "    comby = np.hstack((resy1,dec_y))\n",
        "\n",
        "\n",
        "    ifile = './'+dir_model+'/trn_img_f/' + \\\n",
        "        str(m) + '_trn_img.txt'\n",
        "    np.savetxt(ifile, combx)\n",
        "\n",
        "    \n",
        "    lfile = './'+dir_model+'/trn_lab_f/' + \\\n",
        "        str(m) + '_trn_lab.txt'\n",
        "    np.savetxt(lfile,comby) \n",
        "    print()\n",
        "\n",
        "t1 = time.time()\n",
        "print('final time(min): {:.2f}'.format((t1 - t0)/60))"
      ],
      "metadata": {
        "id": "gHibGtVs6FKh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        },
        "outputId": "d97cc1f9-d781-4cb5-cae4-5dfb9658bc9b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Len yclass 6742\n",
            "2000\n",
            "Len yclass 5958\n",
            "3000\n",
            "Len yclass 6131\n",
            "3250\n",
            "Len yclass 5842\n",
            "3500\n",
            "Len yclass 5421\n",
            "3650\n",
            "Len yclass 5918\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-c62f5302f5a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Len yclass\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myclass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimbal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mimbal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mxsamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mysamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG_SM1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxclass\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myclass\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mysamp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-31302d20f6e5>\u001b[0m in \u001b[0;36mG_SM1\u001b[0;34m(X, y, n_to_sample, cl)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mknn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNearestNeighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_neigh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;31m# generating samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    757\u001b[0m                     \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meffective_metric_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m                     \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                     \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 )\n\u001b[1;32m    761\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances_chunked\u001b[0;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[1;32m   1715\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1716\u001b[0m             \u001b[0mX_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1717\u001b[0;31m         \u001b[0mD_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpairwise_distances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1718\u001b[0m         if (X is Y or Y is None) and PAIRWISE_DISTANCE_FUNCTIONS.get(\n\u001b[1;32m   1719\u001b[0m             \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances\u001b[0;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[1;32m   1887\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1889\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_parallel_pairwise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1891\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36m_parallel_pairwise\u001b[0;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[1;32m   1428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0meffective_n_jobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1430\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m     \u001b[0;31m# enforce a threading backend to prevent data communication overhead\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36meuclidean_distances\u001b[0;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[0m\n\u001b[1;32m    328\u001b[0m             )\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_euclidean_distances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_norm_squared\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_norm_squared\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msquared\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36m_euclidean_distances\u001b[0;34m(X, Y, X_norm_squared, Y_norm_squared, squared)\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0;31m# To minimize precision issues with float32, we compute the distance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0;31m# matrix on chunks of X and Y upcast to float64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m         \u001b[0mdistances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_euclidean_distances_upcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0;31m# if dtype is already float64, no need to chunk and upcast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36m_euclidean_distances_upcast\u001b[0;34m(X, XX, Y, YY, batch_size)\u001b[0m\n\u001b[1;32m    567\u001b[0m                 \u001b[0md\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mYY_chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m             \u001b[0mdistances\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_slice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_slice\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdistances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "  print(\"Classe\", i)\n",
        "  print(comby.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYtztDQV28U3",
        "outputId": "fe997f6e-f682-454f-c684-51ac9d2c13bf"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classe 0\n",
            "(91000,)\n",
            "Classe 1\n",
            "(91000,)\n",
            "Classe 2\n",
            "(91000,)\n",
            "Classe 3\n",
            "(91000,)\n",
            "Classe 4\n",
            "(91000,)\n",
            "Classe 5\n",
            "(91000,)\n",
            "Classe 6\n",
            "(91000,)\n",
            "Classe 7\n",
            "(91000,)\n",
            "Classe 8\n",
            "(91000,)\n",
            "Classe 9\n",
            "(91000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(combx[5000].reshape(28,28))\n",
        "print(comby[5000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "iVW-ZZaLyavm",
        "outputId": "bef8640e-a321-4221-afc0-75f25d98775b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resnet"
      ],
      "metadata": {
        "id": "KXsLuoCj4BlU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=False)\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "RZZKKAm84Chj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c993746-43eb-4dab-da28-8a762e8f2aea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/pytorch/vision/archive/v0.10.0.zip\" to /root/.cache/torch/hub/v0.10.0.zip\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.backends.cudnn as cudnn\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "\n",
        "cudnn.benchmark = True\n",
        "#plt.ion()   # interactive mode"
      ],
      "metadata": {
        "id": "PLX2vG6l5oh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trnimgfile = '/content/'+dir_model+'/trn_img_f/0_trn_img.txt'\n",
        "trnlabfile = '/content/'+dir_model+'/trn_lab_f/0_trn_lab.txt'\n",
        "\n",
        "dec_x = np.loadtxt(trnimgfile) \n",
        "dec_y = np.loadtxt(trnlabfile)\n",
        "\n",
        "print('train imgs before reshape ',dec_x.shape) \n",
        "print('train labels ',dec_y.shape) \n",
        "print(collections.Counter(dec_y))\n",
        "dec_x = dec_x.reshape(dec_x.shape[0],1,28,28) \n",
        "print('train imgs after reshape ',dec_x.shape) \n",
        "\n",
        "tensor_x = torch.Tensor(dec_x)\n",
        "tensor_y = torch.tensor(dec_y,dtype=torch.long)\n",
        "dataset_bal = TensorDataset(tensor_x,tensor_y) \n",
        "train_loader = torch.utils.data.DataLoader(dataset_bal, batch_size=batch_size,shuffle=True,num_workers=num_workers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeNc85Mk8Iap",
        "outputId": "0525f708-32fa-4c00-ac05-7cadf7ab14e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train imgs before reshape  (91000, 784)\n",
            "train labels  (91000,)\n",
            "Counter({9.0: 9960, 8.0: 9940, 7.0: 9900, 6.0: 9800, 5.0: 9650, 4.0: 9500, 3.0: 9250, 2.0: 9000, 1.0: 8000, 0.0: 6000})\n",
            "train imgs after reshape  (91000, 1, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "7GOr7ieUX62o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJPjUHn8YBpo",
        "outputId": "92a5ee6a-4270-4269-dea5-f198f8428435"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.11.0+cu113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "## transformations\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor()])\n",
        "\n",
        "## download and load training dataset\n",
        "if(chosen_dataset == 'mnist'):\n",
        "  trainset = torchvision.datasets.MNIST(root='./data', train=True,download=True, transform=transform)\n",
        "  testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "if(chosen_dataset == 'fashionmnist'):\n",
        "  trainset = torchvision.datasets.FashionMNIST(root='./data', train=True,download=True, transform=transform)\n",
        "  testset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "trainloader = train_loader#torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,shuffle=True, num_workers=2)\n",
        "\n",
        "## download and load testing dataset\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "VAQkDOlTYM6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "## functions to show an image\n",
        "def imshow(img):\n",
        "    #img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "\n",
        "## get some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "## show images\n",
        "imshow(torchvision.utils.make_grid(images))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "ShGxnjH0YPQY",
        "outputId": "be62a338-6ee5-41c7-e4eb-2e2e22ce2d8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for images, labels in trainloader:\n",
        "    print(\"Image batch dimensions:\", images.shape)\n",
        "    print(\"Image label dimensions:\", labels.shape)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjF7ZfWuYUmg",
        "outputId": "16e31397-4361-4b78-f4c3-20ddc6081245"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image batch dimensions: torch.Size([128, 1, 28, 28])\n",
            "Image label dimensions: torch.Size([128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "\n",
        "        # 28x28x1 => 26x26x32\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3)\n",
        "        self.d1 = nn.Linear(26 * 26 * 32, 128)\n",
        "        self.d2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 32x1x28x28 => 32x32x26x26\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        # flatten => 32 x (32*26*26)\n",
        "        x = x.flatten(start_dim = 1)\n",
        "\n",
        "        # 32 x (32*26*26) => 32x128\n",
        "        x = self.d1(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        # logits => 32x10\n",
        "        logits = self.d2(x)\n",
        "        out = F.softmax(logits, dim=1)\n",
        "        return out"
      ],
      "metadata": {
        "id": "AzUDV7cQYdIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## test the model with 1 batch\n",
        "model = MyModel()\n",
        "for images, labels in trainloader:\n",
        "    print(\"batch size:\", images.shape)\n",
        "    out = model(images)\n",
        "    print(out.shape)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8jkt7xzYtX3",
        "outputId": "bb2f4a3d-aaca-4595-dde8-50b60abb2c83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch size: torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "num_epochs = 5\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = MyModel()\n",
        "model = model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "TCJFCgjuY-YA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## compute accuracy\n",
        "def get_accuracy(logit, target, batch_size):\n",
        "    ''' Obtain accuracy for training round '''\n",
        "    corrects = (torch.max(logit, 1)[1].view(target.size()).data == target.data).sum()\n",
        "    accuracy = 100.0 * corrects/batch_size\n",
        "    return accuracy.item()"
      ],
      "metadata": {
        "id": "nLSGLc7KZAbg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%%time\n",
        "for epoch in range(num_epochs):\n",
        "    train_running_loss = 0.0\n",
        "    train_acc = 0.0\n",
        "\n",
        "    model = model.train()\n",
        "\n",
        "    ## training step\n",
        "    for i, (images, labels) in enumerate(trainloader):\n",
        "        \n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        ## forward + backprop + loss\n",
        "        logits = model(images)\n",
        "        loss = criterion(logits, labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        ## update model params\n",
        "        optimizer.step()\n",
        "\n",
        "        train_running_loss += loss.detach().item()\n",
        "        train_acc += get_accuracy(logits, labels, batch_size)\n",
        "        #print( get_accuracy(logits, labels, batch_size))\n",
        "    \n",
        "    model.eval()\n",
        "    print('Epoch: %d | Loss: %.4f | Train Accuracy: %.2f' \\\n",
        "          %(epoch, train_running_loss / i, train_acc/i)) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xv-o5EZWZF_4",
        "outputId": "526c3542-e274-40fe-b43a-9e5ff8fa889d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | Loss: 1.5023 | Train Accuracy: 96.31\n",
            "Epoch: 1 | Loss: 1.5007 | Train Accuracy: 96.46\n",
            "Epoch: 2 | Loss: 1.4982 | Train Accuracy: 96.73\n",
            "Epoch: 3 | Loss: 1.4964 | Train Accuracy: 96.86\n",
            "Epoch: 4 | Loss: 1.4966 | Train Accuracy: 96.87\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Avaliação e Métricas"
      ],
      "metadata": {
        "id": "99anURkY1Ln3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_acc = 0.0\n",
        "for i, (images, labels) in enumerate(testloader, 0):\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(images)\n",
        "    test_acc += get_accuracy(outputs, labels, BATCH_SIZE)\n",
        "        \n",
        "print('Test Accuracy: %.2f'%( test_acc/i))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tg7xofCWZetS",
        "outputId": "146be601-f12c-4f89-db98-fdda7d8d0804"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 90.81\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "c2S_mUiPQqEA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}