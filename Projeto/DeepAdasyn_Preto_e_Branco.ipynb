{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepAdasyn_Preto_e_Branco.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Inicializações, mkdir"
      ],
      "metadata": {
        "id": "plbr3BQD988Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4FAU1Rv3WjS9"
      },
      "outputs": [],
      "source": [
        "#!pip install torch==1.2.0+cu92 torchvision==0.4.0+cu92 -f https://download.pytorch.org/whl/torch_stable.html"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!mkdir -p MNIST/trn_img/\n",
        "!mkdir -p MNIST/trn_lab/\n",
        "!mkdir -p MNIST/models/crs5/0/\n",
        "!mkdir -p MNIST/models/crs5/1/\n",
        "!mkdir -p MNIST/models/crs5/2/\n",
        "!mkdir -p MNIST/models/crs5/3/\n",
        "!mkdir -p MNIST/models/crs5/4/\n",
        "!mkdir -p MNIST/trn_img_f/\n",
        "!mkdir -p MNIST/trn_lab_f/\n",
        "\n",
        "!mkdir -p FashionMNIST/trn_img/\n",
        "!mkdir -p FashionMNIST/trn_lab/\n",
        "!mkdir -p FashionMNIST/models/crs5/0/\n",
        "!mkdir -p FashionMNIST/models/crs5/1/\n",
        "!mkdir -p FashionMNIST/models/crs5/2/\n",
        "!mkdir -p FashionMNIST/models/crs5/3/\n",
        "!mkdir -p FashionMNIST/models/crs5/4/\n",
        "!mkdir -p FashionMNIST/trn_img_f/\n",
        "!mkdir -p FashionMNIST/trn_lab_f/\n",
        "\n",
        "!mkdir -p CIFAR10/trn_img/\n",
        "!mkdir -p CIFAR10/trn_lab/\n",
        "!mkdir -p CIFAR10/models/crs5/0/\n",
        "!mkdir -p CIFAR10/models/crs5/1/\n",
        "!mkdir -p CIFAR10/models/crs5/2/\n",
        "!mkdir -p CIFAR10/models/crs5/3/\n",
        "!mkdir -p CIFAR10/models/crs5/4/\n",
        "!mkdir -p CIFAR10/trn_img_f/\n",
        "!mkdir -p CIFAR10/trn_lab_f/\n",
        "\n",
        "!mkdir -p SVHN/trn_img/\n",
        "!mkdir -p SVHN/trn_lab/\n",
        "!mkdir -p SVHN/models/crs5/0//models/crs5/0/\n",
        "!mkdir -p SVHN/models/crs5/1//models/crs5/1/\n",
        "!mkdir -p SVHN/models/crs5/2//models/crs5/2/\n",
        "!mkdir -p SVHN/models/crs5/3//models/crs5/3/\n",
        "!mkdir -p SVHN/models/crs5/4//models/crs5/4/\n",
        "!mkdir -p SVHN/trn_img_f/\n",
        "!mkdir -p SVHN/trn_lab_f/\n",
        "\n",
        "\n",
        "!mkdir -p CelebA/trn_img/\n",
        "!mkdir -p CelebA/trn_lab/\n",
        "!mkdir -p CelebA/models/crs5/0//models/crs5/0/\n",
        "!mkdir -p CelebA/models/crs5/1//models/crs5/1/\n",
        "!mkdir -p CelebA/models/crs5/2//models/crs5/2/\n",
        "!mkdir -p CelebA/models/crs5/3//models/crs5/3/\n",
        "!mkdir -p CelebA/models/crs5/4//models/crs5/4/\n",
        "!mkdir -p CelebA/trn_img_f/\n",
        "!mkdir -p CelebA/trn_lab_f/\n"
      ],
      "metadata": {
        "id": "G_eVvGkUVcPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader,TensorDataset,random_split,SubsetRandomSampler, ConcatDataset\n",
        "import numpy as np\n",
        "from sklearn import neighbors\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import time\n",
        "import os\n",
        "import torchvision\n",
        "from torchvision import datasets,transforms\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.model_selection import KFold,StratifiedKFold\n",
        "\n",
        "print(torch.version.cuda) #10.1\n",
        "t3 = time.time()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPZ--wCV4y_X",
        "outputId": "94d29f8a-b5d8-40e5-b138-670a6648e461"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Argumentos"
      ],
      "metadata": {
        "id": "W9WH7FJWkX05"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##############################################################################\n",
        "\"\"\"args for AE\"\"\"\n",
        "\n",
        "#MNIST e FMNIST n_channel = 1 e n_z = 300\n",
        "#Cifar10 e SVHN n_channel = 3 e n_z = 600\n",
        "\n",
        "args = {}\n",
        "args['dim_h'] = 64         # factor controlling size of hidden layers\n",
        "args['n_channel'] = 1 #1  ou 3    # number of channels in the input data \n",
        "\n",
        "args['n_z'] = 300 #300 ou 600     # number of dimensions in latent space. \n",
        "\n",
        "args['sigma'] = 1.0        # variance in n_z\n",
        "args['lambda'] = 0.01      # hyper param for weight of discriminator loss\n",
        "args['lr'] = 0.0002        # learning rate for Adam optimizer .000\n",
        "args['epochs'] = 10       # how many epochs to run for\n",
        "args['batch_size'] = 100   # batch size for SGD\n",
        "args['save'] = True        # save weights at each epoch of training if True\n",
        "args['train'] = True       # train networks if True, else load networks from\n",
        "\n",
        "args['dataset'] = 'fashionmnist' # 'mnist' ou 'fashionmnist' ou 'cifar10' ou 'svhn'  # specify which dataset to use\n",
        "#args['oversampling'] = 'smote' # 'smote' ou 'adasyn'\n",
        "args['resnet_learning_rate'] = 0.001\n",
        "args['resnet_num_epochs'] = 5\n",
        "\n"
      ],
      "metadata": {
        "id": "w3fvtoUo48SS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importando os datasets "
      ],
      "metadata": {
        "id": "epukq3tXNmzH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###############################################################################\n",
        "\n",
        "\n",
        "#NOTE: Download the training ('.../0_trn_img.txt') and label files \n",
        "# ('.../0_trn_lab.txt').  Place the files in directories (e.g., ../MNIST/trn_img/\n",
        "# and /MNIST/trn_lab/).  Originally, when the code was written, it was for 5 fold\n",
        "#cross validation and hence there were 5 files in each of the \n",
        "#directories.  Here, for illustration, we use only 1 training and 1 label\n",
        "#file (e.g., '.../0_trn_img.txt' and '.../0_trn_lab.txt').\n",
        "\n",
        "## transformation\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if( args['dataset']== 'mnist'):\n",
        "  #transform = transforms.Compose([transforms.ToTensor(), transforms.Resize(size=(28,28))])\n",
        "  #dataset_torch = datasets.MNIST(root='./', train=True, download=True, transform=transform)\n",
        "  train_dataset = torchvision.datasets.MNIST(root='./',  train=True, download=True)\n",
        "  test_dataset  = torchvision.datasets.MNIST(root='./',  train=False, download=True)\n",
        "  dir_model = 'MNIST'\n",
        "  print(\"Mnist\")\n",
        "elif( args['dataset']== 'fashionmnist'):\n",
        "  #transform = transforms.Compose([transforms.ToTensor(), transforms.Resize(size=(28,28))])\n",
        "  #dataset_torch = datasets.FashionMNIST(root='./', train=True, download=True, transform=transform)\n",
        "  train_dataset = torchvision.datasets.FashionMNIST(root='./',  train=True, download=True)\n",
        "  test_dataset  = torchvision.datasets.FashionMNIST(root='./',  train=False, download=True)\n",
        "  dir_model = 'FashionMNIST'\n",
        "  print(\"FashionMNIST\")\n",
        "elif( args['dataset']== 'cifar10'):\n",
        "  #transform = transforms.Compose( [transforms.ToTensor(), transforms.Resize(size=(32,32))])\n",
        "  #dataset_torch = datasets.CIFAR10(root='./', train=True, download=True, transform=transform)\n",
        "  train_dataset = torchvision.datasets.CIFAR10(root='./',  train=True, download=True)\n",
        "  test_dataset  = torchvision.datasets.CIFAR10(root='./',  train=False, download=True)\n",
        "  dir_model = 'CIFAR10'\n",
        "  print(\"CIFAR10\")\n",
        "elif( args['dataset']== 'svhn'):\n",
        "  #transform = transforms.Compose( [transforms.ToTensor(), transforms.Resize(size=(32,32))])\n",
        "  #dataset_torch = datasets.SVHN(root='./', train=True, download=True, transform=transform)\n",
        "  train_dataset = torchvision.datasets.SVHN(root='./',  train=True, download=True)\n",
        "  test_dataset  = torchvision.datasets.SVHN(root='./',  train=False, download=True)\n",
        "  dir_model = 'SVHN'\n",
        "  print(\"SVHN\")\n",
        "\n",
        "\n",
        "'''\n",
        "\n",
        "!mv MNIST/raw/train-images-idx3-ubyte MNIST/trn_img/0_trn_img.txt\n",
        "!mv MNIST/raw/train-labels-idx1-ubyte MNIST/trn_lab/0_trn_lab.txt\n",
        "dtrnimg = 'MNIST/trn_img/'\n",
        "dtrnlab = 'MNIST/trn_lab/'\n",
        "\n",
        "## download and load training dataset\n",
        "#trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,\n",
        "#                                          shuffle=True, num_workers=2)\n",
        "'''\n",
        "def get_imbalance_train():\n",
        "  if(args['dataset'] =='mnist' or args['dataset'] =='fashionmnist'):\n",
        "    return [4000, 2000, 1000, 750, 500, 350, 200, 100, 60, 40]\n",
        "  elif (args['dataset'] =='cifar10' or args['dataset'] =='svhn'):\n",
        "    return [4500, 2000, 1000, 800, 600, 500, 400, 250, 150, 80]\n",
        "  #else:\n",
        "  #   [4500, 2000, 1000, 800, 600, 500, 400, 250, 150, 80]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dQSVlGI5NxM",
        "outputId": "041ccf0b-f3ed-43d2-ff63-43fe6152589b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "CIFAR10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKm4M6k22ltV",
        "outputId": "5e4b7649-2879-46e5-a6d5-a08e47e7bc63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset CIFAR10\n",
              "    Number of datapoints: 50000\n",
              "    Root location: ./\n",
              "    Split: Train"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor()\n",
        "])\n",
        "\n",
        "train_dataset.transform=transform\n",
        "test_dataset.transform=transform"
      ],
      "metadata": {
        "id": "Ne7XZT9N18Su"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset = ConcatDataset([train_dataset, test_dataset])\n",
        "#tmp = DataLoader(dataset, batch_size=70000, shuffle=True)\n",
        "#dec_x, dec_y = next(iter(tmp))"
      ],
      "metadata": {
        "id": "YA-HiRUYjQPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.manual_seed(42)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "dataset = ConcatDataset([train_dataset, test_dataset])\n",
        "\n",
        "num_epochs=10\n",
        "batch_size=128\n",
        "k=5\n",
        "splits=StratifiedKFold(n_splits=k,shuffle=True,random_state=42)\n",
        "foldperf={}\n",
        "tmp = DataLoader(dataset, batch_size=70000, shuffle=True)\n",
        "dec_x, dec_y = next(iter(tmp))\n",
        "def get_exactly_6000(c,dec_x, dec_y):\n",
        "    \n",
        "    xbeg = dec_x[dec_y == c]\n",
        "    ybeg = dec_y[dec_y == c]\n",
        "    \n",
        "    return [xbeg[0:1200],xbeg[1200:2400],xbeg[2400:3600],xbeg[3600:4800],xbeg[4800:6000]], [ybeg[0:1200],ybeg[1200:2400],ybeg[2400:3600],ybeg[3600:4800],ybeg[4800:6000]]\n",
        "    \n",
        "def generate_balanced_folds(dec_x, dec_y):\n",
        "  X_list = [[],[],[],[],[]]\n",
        "  y_list = [[],[],[],[],[]]\n",
        "  foldsX = []\n",
        "  foldsY = []\n",
        "  for i in range(0,10):\n",
        "    X,y = get_exactly_6000(i,dec_x, dec_y)\n",
        "    print(torch.bincount(y[0]))\n",
        "    for j in range(0,5):\n",
        "      X_list[j].append(X[j])\n",
        "      y_list[j].append(y[j])\n",
        "\n",
        "  for j in range(0,5):\n",
        "    X = torch.cat(X_list[j])\n",
        "    y = torch.cat(y_list[j])\n",
        "    foldsX.append(X)\n",
        "    foldsY.append(y)\n",
        "    \n",
        "  return foldsX, foldsY"
      ],
      "metadata": {
        "id": "F5kYM22q2ABv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "foldsX, foldsY = generate_balanced_folds(dec_x, dec_y)\n",
        "del dec_x\n",
        "del dec_y\n",
        "del tmp\n",
        "del dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZHlWvo42TuE",
        "outputId": "c5c770df-8c82-46a5-9aa1-e710e927dc26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1200])\n",
            "tensor([   0, 1200])\n",
            "tensor([   0,    0, 1200])\n",
            "tensor([   0,    0,    0, 1200])\n",
            "tensor([   0,    0,    0,    0, 1200])\n",
            "tensor([   0,    0,    0,    0,    0, 1200])\n",
            "tensor([   0,    0,    0,    0,    0,    0, 1200])\n",
            "tensor([   0,    0,    0,    0,    0,    0,    0, 1200])\n",
            "tensor([   0,    0,    0,    0,    0,    0,    0,    0, 1200])\n",
            "tensor([   0,    0,    0,    0,    0,    0,    0,    0,    0, 1200])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(transforms.ToPILImage()(foldsX[4][5066]))\n",
        "print(foldsY[0][5066])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "9t4Jjg_D5Wx3",
        "outputId": "85a79d8d-8ee5-46ca-bb87-971964f51e99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(4)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classes Encoder e Decoder "
      ],
      "metadata": {
        "id": "j8ciHDDY4-LZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tx4_Xe2nOzJ_"
      },
      "outputs": [],
      "source": [
        "##############################################################################\n",
        "\n",
        "\n",
        "## create encoder model and decoder model\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.n_channel = args['n_channel']\n",
        "        self.dim_h = args['dim_h']\n",
        "        self.n_z = args['n_z']\n",
        "        \n",
        "        # convolutional filters, work excellent with image data\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(self.n_channel, self.dim_h, 4, 2, 1, bias=False),\n",
        "            #nn.ReLU(True),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(self.dim_h, self.dim_h * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(self.dim_h * 2),\n",
        "            #nn.ReLU(True),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(self.dim_h * 2, self.dim_h * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(self.dim_h * 4),\n",
        "            #nn.ReLU(True),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "\n",
        "\n",
        "            # MNIST,FMNIST\n",
        "            nn.Conv2d(self.dim_h * 4, self.dim_h * 8, 4, 2, 1, bias=False),  \n",
        "            \n",
        "            #3d and 32 by 32\n",
        "            #nn.Conv2d(self.dim_h * 4, self.dim_h * 8, 4, 1, 0, bias=False),\n",
        "            \n",
        "            nn.BatchNorm2d(self.dim_h * 8), # 40 X 8 = 320\n",
        "            #nn.ReLU(True),\n",
        "            nn.LeakyReLU(0.2, inplace=True) )#,\n",
        "            #nn.Conv2d(self.dim_h * 8, 1, 2, 1, 0, bias=False))\n",
        "            #nn.Conv2d(self.dim_h * 8, 1, 4, 1, 0, bias=False))\n",
        "        # final layer is fully connected\n",
        "        self.fc = nn.Linear(self.dim_h * (2 ** 3), self.n_z)\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        #print('enc')\n",
        "        #print('input ',x.size()) #torch.Size([100, 3,32,32])\n",
        "        x = self.conv(x)\n",
        "        #print(x.shape)\n",
        "        \n",
        "        x = x.squeeze()\n",
        "        #print(x.shape)\n",
        "        #print('aft squeeze ',x.size()) #torch.Size([128, 320])\n",
        "        #aft squeeze  torch.Size([100, 320])\n",
        "        x = self.fc(x)\n",
        "        #print('out ',x.size()) #torch.Size([128, 20])\n",
        "        #out  torch.Size([100, 300])\n",
        "        return x\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.n_channel = args['n_channel']\n",
        "        self.dim_h = args['dim_h']\n",
        "        self.n_z = args['n_z']\n",
        "\n",
        "        # first layer is fully connected\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(self.n_z, self.dim_h * 8 * 9 *9),\n",
        "            nn.ReLU())\n",
        "\n",
        "        # deconvolutional filters, essentially inverse of convolutional filters\n",
        "        self.deconv = nn.Sequential(\n",
        "            nn.ConvTranspose2d(self.dim_h * 8, self.dim_h * 4, 4),\n",
        "            nn.BatchNorm2d(self.dim_h * 4),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(self.dim_h * 4, self.dim_h * 2, 4),\n",
        "            nn.BatchNorm2d(self.dim_h * 2),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(self.dim_h * 2, self.n_channel, 4, stride=2),\n",
        "            #nn.Sigmoid())\n",
        "            nn.Tanh())\n",
        "\n",
        "    def forward(self, x):\n",
        "        #print('dec')\n",
        "        #print('input ',x.size())\n",
        "        x = self.fc(x)\n",
        "        x = x.view(-1, self.dim_h * 8, 9, 9)\n",
        "        x = self.deconv(x)\n",
        "        return x\n",
        "\n",
        "##############################################################################\n",
        "\"\"\"set models, loss functions\"\"\"\n",
        "# control which parameters are frozen / free for optimization\n",
        "def free_params(module: nn.Module):\n",
        "    for p in module.parameters():\n",
        "        p.requires_grad = True\n",
        "\n",
        "def frozen_params(module: nn.Module):\n",
        "    for p in module.parameters():\n",
        "        p.requires_grad = False\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#encoder_tmp = Encoder(args)\n",
        "#encoder_tmp.eval()"
      ],
      "metadata": {
        "id": "OA50RhwuubY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#encoder_tmp(dec_x[0])"
      ],
      "metadata": {
        "id": "Zr9WrxSRuvdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Treinamento do Encoder/Decoder"
      ],
      "metadata": {
        "id": "clBS35Az5a-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#%%time\n",
        "'''\n",
        "ids = os.listdir(dtrnimg)\n",
        "idtri_f = [os.path.join(dtrnimg, image_id) for image_id in ids]\n",
        "print(idtri_f)\n",
        "\n",
        "ids = os.listdir(dtrnlab)\n",
        "idtrl_f = [os.path.join(dtrnlab, image_id) for image_id in ids]\n",
        "print(idtrl_f)\n",
        "'''\n",
        "\n",
        "def train_enc_dec(dataset_torch, fold_id):\n",
        "  #for i in range(1):\n",
        "  #for i in range(len(ids)):\n",
        "      encoder = Encoder(args)\n",
        "      decoder = Decoder(args)\n",
        "\n",
        "      device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "      print(device)\n",
        "      decoder = decoder.to(device)\n",
        "      encoder = encoder.to(device)\n",
        "\n",
        "      train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "      #decoder loss function\n",
        "      criterion = nn.MSELoss()\n",
        "      criterion = criterion.to(device)\n",
        "      \n",
        "  #    trnimgfile = idtri_f[i]\n",
        "  #    trnlabfile = idtrl_f[i]\n",
        "      \n",
        "  #    print(trnimgfile)\n",
        "  #    print(trnlabfile)\n",
        "  #    dec_x = trnimgfile\n",
        "  #    dec_y = trnlabfile\n",
        "\n",
        "  #    dec_x = \n",
        "  #    dec_y = MNISTtorch.targets\n",
        "  #   print('train imgs before reshape ',dec_x.shape) \n",
        "  #   print('train labels ',dec_y.shape) \n",
        "  #   print(collections.Counter(dec_y))\n",
        "  #   dec_x = dec_x.reshape(dec_x.shape[0],1,28,28)   \n",
        "  #   print('train imgs after reshape ',dec_x.shape) \n",
        "\n",
        "      dl_batch_size = batch_size=dataset_torch.__len__()\n",
        "      batch_size = args['batch_size']\n",
        "      num_workers = 0\n",
        "\n",
        "      #torch.Tensor returns float so if want long then use torch.tensor\n",
        "  #   tensor_x = dec_x\n",
        "  #   tensor_y = MNISTtorch.target\n",
        "  #   mnist_bal = TensorDataset(tensor_x,tensor_y) \n",
        "      train_loader = torch.utils.data.DataLoader(dataset_torch, batch_size=batch_size,shuffle=True,num_workers=num_workers)\n",
        "      \n",
        "      ## Carregar dataset na memória\n",
        "      dl_aux = torch.utils.data.DataLoader(dataset_torch, batch_size=dl_batch_size,shuffle=True,num_workers=num_workers)\n",
        "      \n",
        "      dec_x, dec_y = next(iter(dl_aux))\n",
        "\n",
        "      del dl_aux\n",
        "\n",
        "      classes = (0, 1, 2, 3, 4, 5, 6, 7, 8, 9)\n",
        "\n",
        "      best_loss = np.inf\n",
        "\n",
        "      t0 = time.time()\n",
        "      if args['train']:\n",
        "          enc_optim = torch.optim.Adam(encoder.parameters(), lr = args['lr'])\n",
        "          dec_optim = torch.optim.Adam(decoder.parameters(), lr = args['lr'])\n",
        "      \n",
        "          for epoch in range(args['epochs']):\n",
        "              train_loss = 0.0\n",
        "              tmse_loss = 0.0\n",
        "              tdiscr_loss = 0.0\n",
        "              # train for one epoch -- set nets to train mode\n",
        "              encoder.train()\n",
        "              decoder.train()\n",
        "          \n",
        "              for images,labs in train_loader:\n",
        "              \n",
        "                  # zero gradients for each batch\n",
        "                  encoder.zero_grad()\n",
        "                  decoder.zero_grad()\n",
        "                  #print(images)\n",
        "                  images, labs = images.to(device), labs.to(device)\n",
        "                  #print('images ',images.size()) \n",
        "                  labsn = labs.detach().cpu().numpy()\n",
        "                  #print('labsn ',labsn.shape, labsn)\n",
        "              \n",
        "                  # run images\n",
        "                  z_hat = encoder(images)\n",
        "              \n",
        "                  x_hat = decoder(z_hat) #decoder outputs tanh\n",
        "                  #print('xhat ', x_hat.size())\n",
        "                  #print(x_hat)\n",
        "\n",
        "                  #Reconstruction Loss\n",
        "                  mse = criterion(x_hat,images)\n",
        "                  #print('mse ',mse)\n",
        "                  \n",
        "                        \n",
        "                  resx = []\n",
        "                  resy = []\n",
        "\n",
        "                  #Randomly sample classes            \n",
        "                  tc = np.random.randint(10)\n",
        "                  #tc = 9\n",
        "                  #print(\"Class:\", tc)\n",
        "\n",
        "                  #Randomly sample nsamp instances of that class\n",
        "                  xbeg = dec_x[dec_y == tc]\n",
        "                  ybeg = dec_y[dec_y == tc] \n",
        "                  xlen = len(xbeg)\n",
        "                  #print(\"xlen\", xlen)\n",
        "                  nsamp = min(xlen, 100)\n",
        "                  ind = np.random.choice(list(range(len(xbeg))),nsamp,replace=False)\n",
        "                  xclass = xbeg[ind]\n",
        "                  yclass = ybeg[ind]\n",
        "              \n",
        "                  xclen = len(xclass)\n",
        "                  #print('xclen ',xclen)\n",
        "                  xcminus = np.arange(1,xclen)\n",
        "                  #print('minus ',xcminus.shape,xcminus)\n",
        "                  \n",
        "                  xcplus = np.append(xcminus,0)\n",
        "                  #print('xcplus ',xcplus)\n",
        "                  xcnew = (xclass[[xcplus],:])\n",
        "                  #xcnew = np.squeeze(xcnew)\n",
        "                  xcnew = xcnew.reshape(xcnew.shape[1],xcnew.shape[2],xcnew.shape[3],xcnew.shape[4])\n",
        "                  #print('xcnew ',xcnew.shape)\n",
        "              \n",
        "                  xcnew = torch.Tensor(xcnew)\n",
        "                  xcnew = xcnew.to(device)\n",
        "              \n",
        "                  #Encode xclass to feature space\n",
        "                  xclass = torch.Tensor(xclass)\n",
        "                  xclass = xclass.to(device)\n",
        "                  xclass = encoder(xclass)\n",
        "                  #print('xclass ',xclass.shape) \n",
        "              \n",
        "                  xclass = xclass.detach().cpu().numpy()\n",
        "              \n",
        "                  xc_enc = (xclass[[xcplus],:])\n",
        "                  xc_enc = np.squeeze(xc_enc)\n",
        "                  #print('xc enc ',xc_enc.shape)\n",
        "              \n",
        "                  xc_enc = torch.Tensor(xc_enc)\n",
        "                  xc_enc = xc_enc.to(device)\n",
        "\n",
        "                  #Decode\n",
        "                  ximg = decoder(xc_enc)\n",
        "                  \n",
        "                  #Penalty Loss \n",
        "                  mse2 = criterion(ximg,xcnew)\n",
        "              \n",
        "                  comb_loss = mse2 + mse\n",
        "                  comb_loss.backward()\n",
        "              \n",
        "                  enc_optim.step()\n",
        "                  dec_optim.step()\n",
        "              \n",
        "                  train_loss += comb_loss.item()*images.size(0)\n",
        "                  tmse_loss += mse.item()*images.size(0)\n",
        "                  tdiscr_loss += mse2.item()*images.size(0)\n",
        "              \n",
        "                  \n",
        "              # print avg training statistics \n",
        "              train_loss = train_loss/len(train_loader)\n",
        "              tmse_loss = tmse_loss/len(train_loader)\n",
        "              tdiscr_loss = tdiscr_loss/len(train_loader)\n",
        "              print('Epoch: {} \\tTrain Loss: {:.6f} \\tmse loss: {:.6f} \\tmse2 loss: {:.6f}'.format(epoch,\n",
        "                      train_loss,tmse_loss,tdiscr_loss))\n",
        "              \n",
        "          \n",
        "  #########################5 Way Cross Validation#################################       \n",
        "            #store the best encoder and decoder models\n",
        "              #here, /crs5 is a reference to 5 way cross validation, but is not\n",
        "              #necessary for illustration purposes\n",
        "              if train_loss < best_loss:\n",
        "                  print('Saving..')\n",
        "                  path_enc = dir_model+'/models/crs5/' \\\n",
        "                      + str(fold_id) + '/bst_enc.pth'\n",
        "                  path_dec = dir_model+'/models/crs5/' \\\n",
        "                      + str(fold_id) + '/bst_dec.pth'\n",
        "              \n",
        "                  torch.save(encoder.state_dict(), path_enc)\n",
        "                  torch.save(decoder.state_dict(), path_dec)\n",
        "          \n",
        "                  best_loss = train_loss\n",
        "  ################################################################################        \n",
        "          \n",
        "          #in addition, store the final model (may not be the best) for\n",
        "          #informational purposes\n",
        "          path_enc = dir_model+'/models/crs5/' \\\n",
        "              + str(fold_id) + '/f_enc.pth'\n",
        "          path_dec = dir_model+'/models/crs5/' \\\n",
        "              + str(fold_id) + '/f_dec.pth'\n",
        "          print(path_enc)\n",
        "          print(path_dec)\n",
        "          torch.save(encoder.state_dict(), path_enc)\n",
        "          torch.save(decoder.state_dict(), path_dec)\n",
        "          print()\n",
        "                \n",
        "        #t1 = time.time()\n",
        "        #print('total time(min): {:.2f}'.format((t1 - t0)/60))             \n",
        "  \n",
        "      #t4 = time.time()\n",
        "      #print('final time(min): {:.2f}'.format((t4 - t3)/60))\n",
        "    "
      ],
      "metadata": {
        "id": "nDw9ow66lNS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SMOTE/Adasyn"
      ],
      "metadata": {
        "id": "HvCKOEQ6u9WU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##############################################################################\n",
        "\n",
        "def biased_get_class1(c, dec_x, dec_y):\n",
        "    \n",
        "    xbeg = dec_x[dec_y == c]\n",
        "    ybeg = dec_y[dec_y == c]\n",
        "    \n",
        "    return xbeg, ybeg\n",
        "    #return xclass, yclass\n",
        "'''\n",
        "\n",
        "\n",
        "'''\n",
        "\n",
        "def G_SM1(X, y,n_to_sample,cl):\n",
        "\n",
        "    \n",
        "    # fitting the model\n",
        "    n_neigh = 5 + 1\n",
        "    knn = NearestNeighbors(n_neighbors=n_neigh, n_jobs=1)\n",
        "    knn.fit(X)\n",
        "    dist, ind = knn.kneighbors(X)\n",
        "\n",
        "    # generating samples\n",
        "    base_indices = np.random.choice(list(range(len(X))),n_to_sample)\n",
        "    neighbor_indices = np.random.choice(list(range(1, n_neigh)),n_to_sample)\n",
        "\n",
        "    X_base = X[base_indices]\n",
        "    X_neighbor = X[ind[base_indices, neighbor_indices]]\n",
        "\n",
        "    samples = X_base + np.multiply(np.random.rand(n_to_sample,1),\n",
        "            X_neighbor - X_base)\n",
        "\n",
        "    #use 10 as label because 0 to 9 real classes and 1 fake/smoted = 10\n",
        "    return samples, [cl]*n_to_sample\n",
        "\n",
        "#############################################################################\n",
        "\n"
      ],
      "metadata": {
        "id": "SAckSkq2w7OG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def adasyn(X, y,xclass, yclass,  cl, m_major, m_minor, beta=1):\n",
        "  '''\n",
        "  Inputs:\n",
        "  X: conjunto de dados ordenados por classe (Da classe 0 a 9)\n",
        "  y : conjunto de labels ordenados por classe (Da classe 0 a 9)\n",
        "  xclass: conjunto de dados da classe alvo\n",
        "  yclass: conjunto de labels da classe alvo\n",
        "  cl : classe alvo\n",
        "  m_major : número de instâncias da classe majoritária\n",
        "  m_minor : número de instâncias da classe minoritária (alvo)\n",
        "  beta : parâmetros que controla quantas instâncias são geradas. Default=1\n",
        "  '''\n",
        "  #Número de neighbors\n",
        "  K = 5\n",
        "  d= m_major/m_minor\n",
        "  #if(d>threshold) acaba aqui\n",
        "  G = (m_major-m_minor)*beta\n",
        "  # fitting the model\n",
        "\n",
        "\n",
        "  clf = neighbors.KNeighborsClassifier()\n",
        "  clf.fit(X, y)\n",
        "  Ri = []\n",
        "  Minority_per_xi = []\n",
        "  #print(\"Deu fit\")\n",
        "  #print(xclass.shape)\n",
        "  for i in range(m_minor):\n",
        "    # Returns indices of the closest neighbours, and return it as a list\n",
        "    xi = xclass[i, :].reshape(1, -1)\n",
        "    # Returns indices of the closest neighbours, and return it as a list\n",
        "    neighbours = clf.kneighbors(xi, n_neighbors=K, return_distance=False)[0]\n",
        "    delta=0\n",
        "    for j in neighbours:\n",
        "      if(y[j]!=0):\n",
        "        delta+=1\n",
        "        \n",
        "    Ri.append(delta/K)\n",
        "\n",
        "    #print(\"Delta:\", delta)\n",
        "    minority = []\n",
        "    for index in neighbours:\n",
        "            # Shifted back 1 because indices start at 0\n",
        "            if y[index]==cl:\n",
        "                minority.append(index)\n",
        "    Minority_per_xi.append(minority)\n",
        "  #print(\"Calculei Ri\")\n",
        "  Ri_norm = []\n",
        "  for ri in Ri:\n",
        "    ri_norm = ri / sum(Ri)\n",
        "    Ri_norm.append(ri_norm)\n",
        "  #print(\"Normalizei Ri\")\n",
        "  #assert (sum(Rhat_i) > 0.99)\n",
        "  Gi = []\n",
        "  for r in Ri_norm:\n",
        "    gi = round(r * G)\n",
        "    Gi.append(int(gi)) \n",
        "  syn_data=[]\n",
        "  syn_number =0\n",
        "  #print(\"Calculei Gi\")\n",
        "  for i in range(m_minor):\n",
        "    #gerar classes\n",
        "    neighbor_indices = np.random.choice(list(range(1, K+1)),Gi[i])\n",
        "    for j in range(Gi[i]):\n",
        "        # If the minority list is not empty\n",
        "        if Minority_per_xi[i]:\n",
        "            index = np.random.choice(Minority_per_xi[i])\n",
        "            xzi = X[index, :].reshape(1, -1)\n",
        "            si = xi + (xzi - xi) * np.random.uniform(0, 1)\n",
        "            syn_data.append(si)\n",
        "            syn_number+=1\n",
        "  #print(\"Gerei os exemplos\")\n",
        "  return syn_data, [cl]*syn_number"
      ],
      "metadata": {
        "id": "DDiDNn8wDzmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Samples"
      ],
      "metadata": {
        "id": "u63YabLHNuXs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def GenerateSamples(dataset_torch, fold_id, oversampling_method):\n",
        "  '''\n",
        "  Inputs:\n",
        "  dataset_torch: O dataset\n",
        "  fold_id: O id do fold\n",
        "  oversampling_method: O método de oversampling\n",
        "  '''\n",
        "  np.printoptions(precision=5,suppress=True)\n",
        "  #%time\n",
        "  '''\n",
        "  dtrnimg = '.../0_trn_img.txt'\n",
        "  dtrnlab = '.../0_trn_lab.txt'\n",
        "\n",
        "  ids = os.listdir(dtrnimg)\n",
        "  idtri_f = [os.path.join(dtrnimg, image_id) for image_id in ids]\n",
        "  print(idtri_f)\n",
        "\n",
        "  ids = os.listdir(dtrnlab)\n",
        "  idtrl_f = [os.path.join(dtrnlab, image_id) for image_id in ids]\n",
        "  print(idtrl_f)\n",
        "  '''\n",
        "  #path on the computer where the models are stored\n",
        "  modpth = './' +dir_model+'/models/crs5/'\n",
        "\n",
        "  encf = []\n",
        "  decf = []\n",
        "  \n",
        "  for p in range(5):\n",
        "      enc = modpth + '/' + str(p) + '/bst_enc.pth'\n",
        "      dec = modpth + '/' + str(p) + '/bst_dec.pth'\n",
        "      encf.append(enc)\n",
        "      decf.append(dec)\n",
        "      #print(enc)\n",
        "      #print(dec)\n",
        "      #print()\n",
        "\n",
        "   \n",
        "  \n",
        "   \n",
        "   \n",
        "\n",
        "  '''\n",
        "  trnimgfile = idtri_f[m]\n",
        "  trnlabfile = idtrl_f[m]\n",
        "  print(trnimgfile)\n",
        "  print(trnlabfile)\n",
        "  dec_x = np.loadtxt(trnimgfile) \n",
        "  dec_y = np.loadtxt(trnlabfile)\n",
        "\n",
        "  print('train imgs before reshape ',dec_x.shape) #(44993, 3072) 45500, 3072)\n",
        "  print('train labels ',dec_y.shape) #(44993,) (45500,)\n",
        "\n",
        "  dec_x = dec_x.reshape(dec_x.shape[0],1,28,28)\n",
        "\n",
        "  print('decy ',dec_y.shape)\n",
        "  print(collections.Counter(dec_y))\n",
        "  \n",
        "  print('train imgs after reshape ',dec_x.shape) #(45000,3,32,32)\n",
        "  '''\n",
        "  dl_batch_size = batch_size=dataset_torch.__len__()\n",
        "  batch_size = args['batch_size']\n",
        "  num_workers = 0\n",
        "\n",
        "  #torch.Tensor returns float so if want long then use torch.tensor\n",
        "#   tensor_x = dec_x\n",
        "#   tensor_y = MNISTtorch.target\n",
        "#   mnist_bal = TensorDataset(tensor_x,tensor_y) \n",
        "  #train_loader = torch.utils.data.DataLoader(dataset_torch, batch_size=batch_size,shuffle=True,num_workers=num_workers)\n",
        "  \n",
        "  ## Carregar dataset na memória\n",
        "  dl_aux = torch.utils.data.DataLoader(dataset_torch, batch_size=dl_batch_size,shuffle=True,num_workers=num_workers)\n",
        "  \n",
        "  dec_x, dec_y = next(iter(dl_aux))\n",
        "\n",
        "  del dl_aux\n",
        "\n",
        "  classes = (0, 1, 2, 3, 4, 5, 6, 7, 8, 9)\n",
        "\n",
        "  best_loss = np.inf\n",
        "\n",
        "  \n",
        "  #generate some images \n",
        "  train_on_gpu = torch.cuda.is_available()\n",
        "  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "  \n",
        "  path_enc = encf[fold_id]\n",
        "  path_dec = decf[fold_id]\n",
        "\n",
        "  encoder = Encoder(args)\n",
        "  encoder.load_state_dict(torch.load(path_enc), strict=False)\n",
        "  encoder = encoder.to(device)\n",
        "\n",
        "  decoder = Decoder(args)\n",
        "  decoder.load_state_dict(torch.load(path_dec), strict=False)\n",
        "  decoder = decoder.to(device)\n",
        "\n",
        "  encoder.eval()\n",
        "  decoder.eval()\n",
        "\n",
        "  #imbal = [4500, 2000, 1000, 800, 600, 500, 400, 250, 150, 80]\n",
        "  imbal = get_imbalance_train()\n",
        "  #if(args['dataset'] =='mnist' or args['dataset'] =='fashionmnist'):\n",
        "  #  imbal = [4000, 2000, 1000, 750, 500, 350, 200, 100, 60, 40]\n",
        "\n",
        "\n",
        "  resx = []\n",
        "  resy = []\n",
        "  xclasses=[]\n",
        "  yclasses=[]\n",
        "  #Gerar um conjunto com todas as classes ordenadas\n",
        "  #print(dec_x.shape)\n",
        "  #print(dec_y.shape)\n",
        "  for i in range(0,10):\n",
        "    xclass, yclass = biased_get_class1(i, dec_x, dec_y)\n",
        "    #print(i)\n",
        "    #print(xclass.shape)   \n",
        "    #encode xclass to feature space\n",
        "    xclass = torch.Tensor(xclass)\n",
        "    xclass = xclass.to(device)\n",
        "    xclass = encoder(xclass)\n",
        "\n",
        "        \n",
        "    xclass = xclass.detach().cpu().numpy()\n",
        "    xclasses.append(xclass)\n",
        "    yclasses.append(yclass)\n",
        "  #for k in range(0,10):\n",
        "    #print(k, xclasses[k].shape)\n",
        "  allClasses = np.concatenate(xclasses)\n",
        "  allY = np.concatenate(yclasses)\n",
        "\n",
        "  #Skipando a classe 1\n",
        "  for i in range(1,10):\n",
        "      xclass, yclass = xclasses[i], yclasses[i]\n",
        "      print('Class {}'.format(i))\n",
        "      print(\"Len Class\", len(yclass))\n",
        "      n = imbal[0] - imbal[i]\n",
        "      if(oversampling_method == 'smote'):\n",
        "        xsamp, ysamp = G_SM1(xclass,yclass,n,i)\n",
        "\n",
        "      elif(oversampling_method == 'adasyn'):  \n",
        "        xsamp, ysamp = adasyn(allClasses, allY, xclass, yclass,  i, m_major=imbal[0], m_minor=imbal[i], beta=1)\n",
        "      #print(len(ysamp))\n",
        "\n",
        "      ysamp = np.array(ysamp)\n",
        "\n",
        "  \n",
        "      \"\"\"to generate samples for resnet\"\"\"   \n",
        "      xsamp = torch.Tensor(xsamp)\n",
        "      xsamp = xsamp.to(device)\n",
        "      #xsamp = xsamp.view(xsamp.size()[0], xsamp.size()[1], 1, 1)\n",
        "      ximg = decoder(xsamp)\n",
        "\n",
        "      ximn = ximg.detach().cpu().numpy()\n",
        "      #ximn = np.expand_dims(ximn,axis=1)\n",
        "\n",
        "      resx.append(ximn)\n",
        "      resy.append(ysamp)\n",
        "  del xclasses\n",
        "  del yclasses\n",
        "  del allClasses\n",
        "  del allY\n",
        "  resx1 = np.vstack(resx)\n",
        "  resy1 = np.hstack(resy)\n",
        "  del resx\n",
        "  del resy\n",
        "  #resx1 = np.squeeze(resx1)\n",
        "\n",
        "\n",
        "  resx1 = resx1.reshape(resx1.shape[0],-1)\n",
        "\n",
        "  \n",
        "  dec_x1 = dec_x.reshape(dec_x.shape[0],-1)\n",
        "\n",
        "  combx = np.vstack((resx1,dec_x1))\n",
        "  comby = np.hstack((resy1,dec_y))\n",
        "  del resx1\n",
        "  del dec_x1\n",
        "  del resy1\n",
        "  del dec_y\n",
        "\n",
        "\n",
        "  ifile = './'+dir_model+'/trn_img_f/' + oversampling_method+ \\\n",
        "      str(fold_id) + '_trn_img.txt'\n",
        "  np.savetxt(ifile, combx)\n",
        "\n",
        "  \n",
        "  lfile = './'+dir_model+'/trn_lab_f/' + oversampling_method+ \\\n",
        "      str(fold_id) + '_trn_lab.txt'\n",
        "  np.savetxt(lfile,comby) \n",
        "  print()\n",
        "  return combx, comby\n",
        "\n",
        "  #t1 = time.time()\n",
        "  #print('final time(min): {:.2f}'.format((t1 - t0)/60))"
      ],
      "metadata": {
        "id": "gHibGtVs6FKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resnet"
      ],
      "metadata": {
        "id": "KXsLuoCj4BlU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import resnet18\n",
        "from torch import nn\n",
        "\n",
        "def create_resnet():\n",
        "    model = resnet18(num_classes=10)#torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=False)\n",
        "    if args['dataset'] == 'mnist':\n",
        "      model.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "    model.eval()\n",
        "    return model"
      ],
      "metadata": {
        "id": "4K2OB1wm1aJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resnet_fit(model,num_epochs,trainloader):\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=args['resnet_learning_rate'])\n",
        "  print(\"Fitting Resnet...\")\n",
        "  for epoch in range(num_epochs):\n",
        "        train_running_loss = 0.0\n",
        "        train_acc = 0.0\n",
        "\n",
        "        model = model.train()\n",
        "\n",
        "        ## training step\n",
        "        for i, (images, labels) in enumerate(trainloader):\n",
        "            \n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            ## forward + backprop + loss\n",
        "            logits = model(images)\n",
        "            loss = criterion(logits, labels)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "\n",
        "            ## update model params\n",
        "            optimizer.step()\n",
        "\n",
        "            train_running_loss += loss.detach().item()\n",
        "            train_acc += 0#get_accuracy(logits, labels, batch_size)\n",
        "            #print( get_accuracy(logits, labels, batch_size))\n",
        "        \n",
        "        model.eval()\n",
        "        print('Epoch: %d | Loss: %.4f | Train Accuracy: %.2f'  %(epoch, train_running_loss / i, train_acc/i)) \n",
        "    "
      ],
      "metadata": {
        "id": "9a-oB0_d1iKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resnet_predict(model,inputs):\n",
        "  model.eval()\n",
        "  outputs = model(inputs)\n",
        "  return outputs#acsa,gm,fm"
      ],
      "metadata": {
        "id": "er936UQ23yPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_balanced_dataset(dir_model,oversampling_method,fold_id):\n",
        "  trnimgfile = '/content/'+dir_model+'/trn_img_f/' + oversampling_method + str(fold_id) + '_trn_img.txt'\n",
        "  trnlabfile = '/content/'+dir_model+'/trn_lab_f/' + oversampling_method + str(fold_id) + '_trn_lab.txt'\n",
        "\n",
        "  dec_x = np.loadtxt(trnimgfile) \n",
        "  dec_y = np.loadtxt(trnlabfile)\n",
        "\n",
        "  print('train imgs before reshape ',dec_x.shape) \n",
        "  print('train labels ',dec_y.shape) \n",
        "  print(collections.Counter(dec_y))\n",
        "  dec_x = dec_x.reshape(dec_x.shape[0],1,28,28) \n",
        "  print('train imgs after reshape ',dec_x.shape) \n",
        "\n",
        "  tensor_x = torch.Tensor(dec_x)\n",
        "  del dec_x\n",
        "  tensor_y = torch.tensor(dec_y,dtype=torch.long)\n",
        "  del dec_y\n",
        "  dataset_bal = TensorDataset(tensor_x,tensor_y)\n",
        "  del tensor_x\n",
        "  del tensor_y\n",
        "  train_loader = torch.utils.data.DataLoader(dataset_bal, batch_size=batch_size,shuffle=True,num_workers=1)\n",
        "  return train_loader"
      ],
      "metadata": {
        "id": "SeNc85Mk8Iap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJPjUHn8YBpo",
        "outputId": "e72bdf15-e359-4ebb-82b0-ee9dfd6dcfaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.11.0+cu113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main"
      ],
      "metadata": {
        "id": "fFwSsVUfj60k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def desbalancear_treino(X, y):\n",
        "  '''\n",
        "  if(args['dataset'] =='mnist' or args['dataset'] =='fashionmnist'):\n",
        "    imbal = [4000, 2000, 1000, 750, 500, 350, 200, 100, 60, 40]\n",
        "  elif (args['dataset'] =='cifar10' or args['dataset'] =='svhn'):\n",
        "    imbal = [4500, 2000, 1000, 800, 600, 500, 400, 250, 150, 80]\n",
        "  else:\n",
        "    imbal = [4500, 2000, 1000, 800, 600, 500, 400, 250, 150, 80]\n",
        "    '''\n",
        "  imbal = get_imbalance_train()\n",
        "  new_X =[]\n",
        "  new_Y =[]\n",
        "  for c in range(0,10):\n",
        "    xclass = X[y==c]\n",
        "    yclass = y[y==c]\n",
        "    new_X.append(xclass[0:imbal[c]])\n",
        "    new_Y.append(yclass[0:imbal[c]])\n",
        "  X_imbal = torch.cat(new_X)\n",
        "  Y_imbal = torch.cat(new_Y)\n",
        "  '''\n",
        "      xbeg = dec_x[dec_y == c]\n",
        "    ybeg = dec_y[dec_y == c]\n",
        "  '''\n",
        "  return X_imbal, Y_imbal\n",
        "\n",
        "def desbalancear_test(X, y):\n",
        "  if(args['dataset'] =='mnist' or args['dataset'] =='fashionmnist'):\n",
        "    imbal = [1000, 500, 250, 187, 125, 350, 87, 50, 15, 10]\n",
        "  elif (args['dataset'] =='cifar10' or args['dataset'] =='svhn'):\n",
        "    imbal = [1000, 500, 250, 187, 125, 350, 87, 50, 15, 10]\n",
        "\n",
        "  new_X =[]\n",
        "  new_Y =[]\n",
        "  for c in range(0,10):\n",
        "    xclass = X[y==c]\n",
        "    yclass = y[y==c]\n",
        "    new_X.append(xclass[0:imbal[c]])\n",
        "    new_Y.append(yclass[0:imbal[c]])\n",
        "  X_imbal = torch.cat(new_X)\n",
        "  Y_imbal = torch.cat(new_Y)\n",
        "  '''\n",
        "      xbeg = dec_x[dec_y == c]\n",
        "    ybeg = dec_y[dec_y == c]\n",
        "  '''\n",
        "  return X_imbal, Y_imbal\n",
        "\n",
        "def get_argmax_resnet(output):\n",
        "  argmax=0\n",
        "  max = output.value"
      ],
      "metadata": {
        "id": "uarnaYWL1qdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5-fold Cross-Validation"
      ],
      "metadata": {
        "id": "ViIggBLO7fTU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from imblearn.metrics import geometric_mean_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "metadata": {
        "id": "H8BkGxP6Iw5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def avarage_class_acuracy(cm):\n",
        "  tp_array = np.diag(cm)\n",
        "  amount_classes = tp_array.shape[0]\n",
        "  total = cm.sum()\n",
        "  accuracy_list = np.zeros(amount_classes)\n",
        "  for i in range(0,amount_classes):\n",
        "    tpi = tp_array[i]\n",
        "    fpi = cm[:,i].sum() - tpi\n",
        "    fni = cm[i,:].sum() - tpi\n",
        "    tni = total - fni - fpi - tpi\n",
        "    acci = (tpi + tni)/(tpi+ tni + fpi + fni)\n",
        "    accuracy_list[i] = acci\n",
        "  return accuracy_list.mean()\n"
      ],
      "metadata": {
        "id": "_mRDrvctFPYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_repeats = 1"
      ],
      "metadata": {
        "id": "fauKn6A8BYDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acs_array_smote_total = np.zeros(num_repeats)\n",
        "gm_array_smote_total = np.zeros(num_repeats)\n",
        "f1macro_array_smote_total = np.zeros(num_repeats)\n",
        "acs_array_adasyn_total = np.zeros(num_repeats)\n",
        "gm_array_adasyn_total = np.zeros(num_repeats)\n",
        "f1macro_array_adasyn_total = np.zeros(num_repeats)"
      ],
      "metadata": {
        "id": "Wsg-UZmCBKMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import shutil"
      ],
      "metadata": {
        "id": "M7APMX1rXL_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_df = pd.DataFrame(columns=['acs_array_smote_total', 'gm_array_smote_total', 'f1macro_array_smote_total', 'acs_array_adasyn_total', 'gm_array_adasyn_total', 'f1macro_array_adasyn_total'])"
      ],
      "metadata": {
        "id": "Fg0sh-8ZWRPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "G8VNNhEOe-6s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67a6a514-b5b7-489a-a743-2b1cdeb55a87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "for repeats in range(0,num_repeats): \n",
        "  #repeats = 0\n",
        "  acs_array_smote = np.zeros(5)\n",
        "  gm_array_smote = np.zeros(5)\n",
        "  f1macro_array_smote = np.zeros(5)\n",
        "  acs_array_adasyn = np.zeros(5)\n",
        "  gm_array_adasyn = np.zeros(5)\n",
        "  f1macro_array_adasyn = np.zeros(5)\n",
        "  print('Repetição {}'.format(repeats+1))\n",
        "  for i in range(0,5):\n",
        "\n",
        "    #i=0\n",
        "    aux_X = foldsX.copy()\n",
        "    aux_Y = foldsY.copy()\n",
        "    print('Fold {}'.format(i + 1))\n",
        "    testX = foldsX[i]\n",
        "    testY = foldsY[i]\n",
        "    aux_X.pop(i)\n",
        "    aux_Y.pop(i)\n",
        "    trainX = torch.cat(aux_X)\n",
        "    trainY = torch.cat(aux_Y)\n",
        "    trainX_imbal, trainY_imbal = desbalancear_treino(trainX, trainY)\n",
        "    dataset_train = torch.utils.data.TensorDataset(trainX_imbal, trainY_imbal)\n",
        "    train_loader = DataLoader(dataset_train, batch_size=48000)\n",
        "\n",
        "    #dataset_test_bal = torch.utils.data.TensorDataset(testX, testY)\n",
        "    #test_loader_bal = DataLoader(dataset_test_bal, batch_size=12000)\n",
        "    print(\"Training enc_dec...\")\n",
        "    train_enc_dec(dataset_train, i)\n",
        "    print(\"Trained enc_dec\")\n",
        "    for oversampling_method in ['smote', 'adasyn']:\n",
        "      print('Method: {}'.format(oversampling_method))\n",
        "      print(\"Generating Samples...\")\n",
        "      #combx, comby = GenerateSamples(dataset_train, i, oversampling_method=oversampling_method)\n",
        "      GenerateSamples(dataset_train, i, oversampling_method=oversampling_method)\n",
        "      print(\"Generated Samples\")\n",
        "      #for j in range(10):\n",
        "        #print(\"Classe\", j)\n",
        "        #print(combx[comby==j].shape)\n",
        "\n",
        "      #plt.imshow(combx[1].reshape(28,28))\n",
        "      #resnet()\n",
        "      #print(comby[1])\n",
        "\n",
        "      # create, fit and predict with resnet\n",
        "\n",
        "      device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "      print(\"Creating Resnet...\")\n",
        "      model = create_resnet()\n",
        "      model.to(device) \n",
        "      aux = testX.to(device) \n",
        "      resnet_trainloader = get_balanced_dataset(dir_model,oversampling_method,i)\n",
        "      print(\"Carregou trainloader da Resnet\")\n",
        "      resnet_fit(model, args['resnet_num_epochs'], resnet_trainloader)\n",
        "      print(\"Predicting outputs...\")\n",
        "      resnet_outputs = resnet_predict(model,aux)\n",
        "\n",
        "      # compute results\n",
        "      classification_result = [torch.argmax(resnet_outputs[i]).item() for i in range(12000)]\n",
        "      y_labels = [testY[i].item() for i in range(12000)]\n",
        "      print(\"Calculating Metrics...\")\n",
        "      # get metrics\n",
        "      f1_macro = f1_score(classification_result, y_labels, average='macro')\n",
        "      gm=geometric_mean_score(y_labels, classification_result, average='macro')\n",
        "      cm=confusion_matrix(y_labels, classification_result)\n",
        "      acs = avarage_class_acuracy(cm) \n",
        "\n",
        "      #store metrics\n",
        "      if oversampling_method == 'smote':\n",
        "        acs_array_smote[i] = acs\n",
        "        gm_array_smote[i] = gm\n",
        "        f1macro_array_smote[i] = f1_macro\n",
        "      else:\n",
        "        acs_array_adasyn[i] = acs\n",
        "        gm_array_adasyn[i] = gm\n",
        "        f1macro_array_adasyn[i] = f1_macro\n",
        "\n",
        "  print(\"Saving on Google Drive\")\n",
        "  acs_array_smote_total[repeats] = acs_array_smote.mean() \n",
        "  gm_array_smote_total[repeats] = gm_array_smote.mean() \n",
        "  f1macro_array_smote_total[repeats] = f1macro_array_smote.mean() \n",
        "  acs_array_adasyn_total[repeats] = acs_array_adasyn.mean() \n",
        "  gm_array_adasyn_total[repeats] = gm_array_adasyn.mean() \n",
        "  f1macro_array_adasyn_total[repeats] = f1macro_array_adasyn.mean()\n",
        "  result_df.loc[len(result_df.index)] = [acs_array_smote_total[repeats],gm_array_smote_total[repeats],f1macro_array_smote_total[repeats],acs_array_adasyn_total[repeats],gm_array_adasyn_total[repeats],f1macro_array_adasyn_total[repeats]]\n",
        "  \n",
        "  file_name = 'data_{}.csv'.format(repeats)\n",
        "  dst = '/content/drive/MyDrive/deep_smote/' + file_name\n",
        "  result_df.to_csv(file_name, mode='a',index=False)      \n",
        "  shutil.copyfile(file_name, dst)\n",
        "\n",
        "    \n",
        "\n"
      ],
      "metadata": {
        "id": "8ourTpH6ai5s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cb88767-e5ae-4870-d888-60a69512b3be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Repetição 1\n",
            "Fold 1\n",
            "Training enc_dec...\n",
            "cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:127: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 \tTrain Loss: 17.824668 \tmse loss: 8.862070 \tmse2 loss: 8.962598\n",
            "Saving..\n",
            "Epoch: 1 \tTrain Loss: 5.523608 \tmse loss: 2.614816 \tmse2 loss: 2.908791\n",
            "Saving..\n",
            "Epoch: 2 \tTrain Loss: 4.242593 \tmse loss: 1.951584 \tmse2 loss: 2.291008\n",
            "Saving..\n",
            "Epoch: 3 \tTrain Loss: 3.659428 \tmse loss: 1.711642 \tmse2 loss: 1.947786\n",
            "Saving..\n",
            "Epoch: 4 \tTrain Loss: 3.298243 \tmse loss: 1.525276 \tmse2 loss: 1.772967\n",
            "Saving..\n",
            "Epoch: 5 \tTrain Loss: 2.971675 \tmse loss: 1.348746 \tmse2 loss: 1.622930\n",
            "Saving..\n",
            "Epoch: 6 \tTrain Loss: 2.755115 \tmse loss: 1.242268 \tmse2 loss: 1.512847\n",
            "Saving..\n",
            "Epoch: 7 \tTrain Loss: 2.537215 \tmse loss: 1.158764 \tmse2 loss: 1.378451\n",
            "Saving..\n",
            "Epoch: 8 \tTrain Loss: 2.391546 \tmse loss: 1.098195 \tmse2 loss: 1.293351\n",
            "Saving..\n",
            "Epoch: 9 \tTrain Loss: 2.267029 \tmse loss: 1.062385 \tmse2 loss: 1.204644\n",
            "Saving..\n",
            "CIFAR10/models/crs5/0/f_enc.pth\n",
            "CIFAR10/models/crs5/0/f_dec.pth\n",
            "\n",
            "Trained enc_dec\n",
            "Method: smote\n",
            "Generating Samples...\n",
            "Class 1\n",
            "Len Class 2000\n",
            "Class 2\n",
            "Len Class 1000\n",
            "Class 3\n",
            "Len Class 800\n",
            "Class 4\n",
            "Len Class 600\n",
            "Class 5\n",
            "Len Class 500\n",
            "Class 6\n",
            "Len Class 400\n",
            "Class 7\n",
            "Len Class 250\n",
            "Class 8\n",
            "Len Class 150\n",
            "Class 9\n",
            "Len Class 80\n",
            "\n",
            "Generated Samples\n",
            "Creating Resnet...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!cp data.csv /content/drive/MyDrive/deep_smote"
      ],
      "metadata": {
        "id": "1LiZW93me6J4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Avaliação e Métricas"
      ],
      "metadata": {
        "id": "99anURkY1Ln3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nesta seção primeiramente é realizado o teste de Shapiro-Wilk para avaliar se as distribuições das métricas avaliadas seguem uma distribuição normal.\n",
        "\n",
        "Caso todas as distribuições sigam a distribuição normal o teste t-student é utilizado para avaliar a independência entre as distribuições das métricas em cada modelo. Caso contrário o teste de Wilcoxon é utilizado."
      ],
      "metadata": {
        "id": "Nii4nJMz18My"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Shapiro-Wilk para testar normalidade:"
      ],
      "metadata": {
        "id": "J3SSTe4gvVVp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import shapiro\n",
        "shapiro_p_value_array = np.zeros(6)\n",
        "# execute shapiro-wilk test for normality on metrics distributions\n",
        "i=0\n",
        "for column in result_df.columns:\n",
        "  data = result_df[column]\n",
        "  stat, p = shapiro(data)\n",
        "  print('stat=%.3f, p=%.3f' % (stat, p))\n",
        "  shapiro_p_value_array[i] = p\n",
        "  if p > 0.05:\n",
        "    print('H0 not rejected for {} metric: Probably Gaussian'.format(column))\n",
        "  else:\n",
        "    print('H0 rejected for {} metric: Probably not Gaussian'.format(column))\n",
        "  i +=1"
      ],
      "metadata": {
        "id": "uSFtrCr-s-W_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def check_array(array):\n",
        "    if np.all(array > 0.05):\n",
        "        return True\n",
        "    else:\n",
        "        return False"
      ],
      "metadata": {
        "id": "szR1bIxHvoes"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_distributions_are_normal = check_array(shapiro_p_value_array)"
      ],
      "metadata": {
        "id": "zmzmp7BbxAmt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_distributions_are_normal"
      ],
      "metadata": {
        "id": "NpN_HZjTxTUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_df"
      ],
      "metadata": {
        "id": "v6R7V9Y-0O2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parametric Test: t-student"
      ],
      "metadata": {
        "id": "QkWUbjH0y3QQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metric_name = ['acs','gm','f1']"
      ],
      "metadata": {
        "id": "47vRIm1N0i6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of the Student's t-test\n",
        "from scipy.stats import ttest_ind\n",
        "if all_distributions_are_normal:\n",
        "  for i in range(0,3):\n",
        "    columns = result_df.columns\n",
        "\n",
        "    data1 = result_df[columns[i]]\n",
        "    data2 = result_df[columns[i+3]]\n",
        "    \n",
        "    stat, p = ttest_ind(data1, data2)\n",
        "    print('stat=%.3f, p=%.3f' % (stat, p))\n",
        "    if p > 0.05:\n",
        "      print('H0 not rejected for {} metric: Probably the same distribution'.format(metric_name[i]))\n",
        "    else:\n",
        "      print('H0 rejected for {} metric: Probably different distributions'.format(metric_name[i]))"
      ],
      "metadata": {
        "id": "KOr4dKXIxoTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Non-parametric Test: Wilcoxon Signed-Rank Test"
      ],
      "metadata": {
        "id": "44XgfYsn1P7j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of the Student's t-test\n",
        "from scipy.stats import wilcoxon\n",
        "if all_distributions_are_normal == False:\n",
        "  for i in range(0,3):\n",
        "    columns = result_df.columns\n",
        "\n",
        "    data1 = result_df[columns[i]]\n",
        "    data2 = result_df[columns[i+3]]\n",
        "    \n",
        "    stat, p = wilcoxon(data1, data2)\n",
        "    print('stat=%.3f, p=%.3f' % (stat, p))\n",
        "    if p > 0.05:\n",
        "      print('H0 not rejected for {} metric: Probably the same distribution'.format(metric_name[i]))\n",
        "    else:\n",
        "      print('H0 rejected for {} metric: Probably different distributions'.format(metric_name[i]))"
      ],
      "metadata": {
        "id": "grcBIQMe1gbN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}