{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Questão_04_REDES_NEURAIS.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ewBiBjs4kkyu",
        "XRRF9s57k_gT"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Questão 21.4\n",
        "For Example (20.1), establish the QP problem, given by (21.7)-(21.9), for SVM learning. \\\\\n",
        "Solve $\\alpha_p$, for $p = 1, ..., 4.$"
      ],
      "metadata": {
        "id": "ewBiBjs4kkyu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example (20.1)\n",
        "Define the kernel $k(\\mathbf{x},\\mathbf{x_i}) = (1 + \\mathbf{x^T}\\mathbf{x_i})^2,$ where $\\mathbf{x} = (x_1,x_2)^T$ and $\\mathbf{x_i} = (x_{i1}, x_{i2})^T.$\n",
        "The training samples $\\mathbf{x_1} = (-1,-1)$ and $\\mathbf{x_4} = (+1,+1)$ belong to class 0, and $\\mathbf{x_2} = (-1,+1), \\mathbf{x_3} = (+1,-1)$ to class 1. \\\\\n",
        "\n",
        "Expanding the kernel function, we have \\\\\n",
        "$k(\\mathbf{x}, \\mathbf{x_i}) = 1 + x_1^2x_{i1}^2 + 2x_1x_2x_{i1}x_{i2} + x_2^2x_{i2}^2 +2x_1x_{i1} +2x_2x_{i2} = \\phi(\\mathbf{x}) \\cdot \\phi(\\mathbf{x_i}),$ \\\\\n",
        "where \\\\\n",
        "$\\phi(\\mathbf{x}) = (1,x_1^2, \\sqrt{2}x_1x_2, x_2^2, \\sqrt{2}x_1, \\sqrt{2}x_2)^T, $ \\\\\n",
        "$\\phi(\\mathbf{x_i}) =  (1, x_{i1}^2, \\sqrt{2}x_{i1}x_{i2}, x_{i2}^2, \\sqrt{2}x_{i1}, \\sqrt{2}x_{i2})^T.$\n",
        "The feature space defined by $\\phi(\\mathbf{x})$ is six-dimensional. To discriminate the four examples in the feature space, we define the decision boundary in $x_1x_2 = 0$. When $x_1x_2 \\ge 0$, an example is categorized into class 0, and otherwise into class 1.\n",
        "\n"
      ],
      "metadata": {
        "id": "XRRF9s57k_gT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Equações (21.7)-(21.9)\n",
        "By applying the Lagrange multiplier method and replacing $\\mathbf{x}_p^T\\mathbf{x}$ by the kernel function $k(\\mathbf{x}_p,\\mathbf{x})$, the ultimate objective of SVM learning is to find $\\alpha_p$, for $ p = 1, ..., N$, so as to minimize the dual quadratic form \\\\\n",
        "- (21.7) $E_{SVM} = \\frac{1}{2} \\sum_{p=1}^N\\sum_{i=1}^N y_py_ik(\\mathbf{x}_p,\\mathbf{x}_i)\\alpha_p\\alpha_i - \\sum_{p=1}^N \\alpha_p$ \\\\\n",
        "\n",
        "subject to \\\\\n",
        "\n",
        "- (21.8) $\\sum_{p=1}^N y_p\\alpha_p = 0 $, \\\\\n",
        "- (21.9) $0 \\le \\alpha_p \\le C$, for $p = 1,...,N$, \\\\\n",
        "where $\\alpha_p$ is the weight for the kernel corresponding to the $p$th example. The kernel function $k(\\mathbf{x}_p,\\mathbf{x}) = \\phi^T(\\mathbf{x}_p)\\phi(\\mathbf{x})$, where the form of $\\phi(\\cdot)$ is implicitly defined by the choice of the kernel function and does not need to be given. When $k(\\cdot)$ is a linear function, that is, $k(\\mathbf{x}_p,\\mathbf{x}) = \\mathbf{x}_p^T\\mathbf{x}$, SVM reduces to linear SVM. The popular Gaussian and polynomial kernels are, respectively given by \\\\\n",
        "$k(\\mathbf{x}_i,\\mathbf{x}_j) = e^{-||x_i - x_j||^2/(2\\sigma^2)} $ \\\\\n",
        "and \\\\\n",
        "$k(\\mathbf{x}_i,\\mathbf{x}_j) = (\\mathbf{x}_i^T\\mathbf{x}_j + \\theta)^m$, \\\\\n",
        "where $m$ is a positive integer, $\\sigma > 0$, and $\\theta \\in R$."
      ],
      "metadata": {
        "id": "c6ZXUsDRrJDY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- (21.7) $E_{SVM} = \\frac{1}{2} \\sum_{p=1}^N\\sum_{i=1}^N y_py_ik(\\mathbf{x}_p,\\mathbf{x}_i)\\alpha_p\\alpha_i - \\sum_{p=1}^N \\alpha_p$ "
      ],
      "metadata": {
        "id": "vosLgOWKw1oS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- (21.8) $\\sum_{p=1}^N y_p\\alpha_p = 0 $"
      ],
      "metadata": {
        "id": "doC16kAFw7SQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- (21.9) $0 \\le \\alpha_p \\le C$, for $p = 1,...,N$"
      ],
      "metadata": {
        "id": "uQSjlCE1xAjn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para a questão temos que encontrar os valores de $α_p$ que minimizem a função $E_{SVM}$ (Definida em 21.7), atendendo às restrições (21.8) e (21.9). Tudo isso aplicado ao exemplo 20.1. Notemos que as restrições possuem C como um parâmetro livre. Trata-se de um problema de otimização. Para isso, utilizaremos a biblioteca SciPy. "
      ],
      "metadata": {
        "id": "StKo8lG62oIp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as pltcolors\n",
        "from scipy import optimize\n"
      ],
      "metadata": {
        "id": "l6yKAQfXxBVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementando a função de Kernel e colocando os inputs em um vetor $x$"
      ],
      "metadata": {
        "id": "qKkgdbW34fVX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def kernel(x1, x2):\n",
        "  return (1+np.matmul(x1.T,x2))**2"
      ],
      "metadata": {
        "id": "n7lpp27GUe1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([[-1,-1], [-1,1], [1,-1], [1,1]])"
      ],
      "metadata": {
        "id": "cJ-T5isHe0O9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos imprimir o valor dos kernels para as instâncias"
      ],
      "metadata": {
        "id": "fnfq8U344tfe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "KernelMatrix = np.zeros((4,4))\n",
        "for i in range(4):\n",
        "  for j in range(4):\n",
        "    KernelMatrix[i][j]=kernel(x[i], x[j])\n",
        "print(KernelMatrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cj5AHNzPtIxq",
        "outputId": "69e69e22-5298-4dac-c95f-4f3e84644a06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[9. 1. 1. 1.]\n",
            " [1. 9. 1. 1.]\n",
            " [1. 1. 9. 1.]\n",
            " [1. 1. 1. 9.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notamos que o kernel tem uma certa simetria e não depende dos valores de i e j, apenas se são iguais ou não. De forma geral, $k(x_i, x_j)$ = 9, se $i=j$ ou 1, se $i\\neq j$. "
      ],
      "metadata": {
        "id": "t2S5BXLD46Qe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para a utilização do algoritmo, devemos trabalhar com as classes -1 ou +1, ou seja, que $y_i\\in \\{-1,+1\\}$ Em seguida, os samples 1 e 4, que estão na classe 0 do exemplo 20.1, são codificados para a classe -1 para o nosso problema, e os samples 2 e 3, que eram da classe 1 no exemplo 20.1, ficam na classe +1."
      ],
      "metadata": {
        "id": "tdeBInMS6BNH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y= np.array([-1,1,1,-1])"
      ],
      "metadata": {
        "id": "Rx2PC2whfBKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora, vamos implementar o Problema Quadrático, as restrições (21.8) e (21.9), e implementar o vetor gradiente do problema quadrático em relação a $\\alpha_p$, pois isso ajuda o resolver a otimização. Inicialmente, fixamos $C=1$, mas também testamos valores maiores e o resultado do alpha dá o mesmo. Quando informamos as restrições, também informo o gradiente das restrições."
      ],
      "metadata": {
        "id": "ZcGypYMF7nc9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n=4\n",
        "# Definindo o problema quadrático\n",
        "def QuadraticProblem( alpha):\n",
        "  Error = 0\n",
        "  for p in range(n):\n",
        "    for i in range(n):\n",
        "      Error+= (0.5)*y[p]*y[i]*kernel(x[i], x[p])*alpha[p]*alpha[i]\n",
        "    Error -= alpha[p]\n",
        "  return Error\n",
        "\n",
        "#Derivada em relação a alpha_p do problema quadrático\n",
        "\n",
        "def QuadraticProblemGrad(alpha):\n",
        "  sum = np.zeros(n)\n",
        "\n",
        "  for p in range(n):\n",
        "    for i in range(n):\n",
        "      sum[p]+= y[p]*y[i]*kernel(x[i], x[p])*alpha[i]\n",
        "    sum[p] -= 1\n",
        "  return sum \n",
        "\n",
        "#Restrição (21.8)\n",
        "def constraint1(alpha):\n",
        "  sum = 0\n",
        "  for i in range(n):\n",
        "    sum+= y[i]*alpha[i]\n",
        "  return sum\n",
        "\n",
        "#Restrição (21.9), os bounds\n",
        "C=1\n",
        "b = (0, C)\n",
        "bounds1 =(b,b,b,b)\n",
        "\n",
        "#Informamos a lista de restrições. Também informamos o gradiente da restrição em relação a $alpha_p$\n",
        "constraints_list = ({'type': 'eq',   'fun': lambda a:  constraint1(a), 'jac': lambda a: y})\n",
        "\n"
      ],
      "metadata": {
        "id": "vY3piaQRUr--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Realizando a otimização"
      ],
      "metadata": {
        "id": "JRrJsvG6-xTh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optRes = optimize.minimize(fun=lambda a: QuadraticProblem(a),\n",
        "                              x0=np.ones(n), \n",
        "                              method='SLSQP', \n",
        "                              jac=lambda a: QuadraticProblemGrad(a), \n",
        "                              constraints= constraints_list, bounds = bounds1)\n"
      ],
      "metadata": {
        "id": "cwlhlSEveTj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optRes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lk0wF7h_iiDr",
        "outputId": "2394302a-8325-48ba-d211-5995aeab30ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     fun: -0.25\n",
              "     jac: array([ 2.22044605e-16, -4.44089210e-16,  4.44089210e-16, -4.44089210e-16])\n",
              " message: 'Optimization terminated successfully.'\n",
              "    nfev: 3\n",
              "     nit: 3\n",
              "    njev: 3\n",
              "  status: 0\n",
              " success: True\n",
              "       x: array([0.125, 0.125, 0.125, 0.125])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imprimindo os $\\alpha_p$ resultante"
      ],
      "metadata": {
        "id": "9Uejdp34_k5N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alpha_resultante = optRes.x\n",
        "print(alpha_resultante)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khAGr-RVh-x5",
        "outputId": "13b6ea27-1121-43c0-db91-c760e0a0e2a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.125 0.125 0.125 0.125]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Temos então que $α_p=0.125$, para todos os $p=1,2,3,4$. Podemos variar o valor de C para ver se encontramos diferenças. Fazendo C=10 e C=100, temos:"
      ],
      "metadata": {
        "id": "95wGMKT5_r9Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para C=10"
      ],
      "metadata": {
        "id": "wxRLL_fCALrp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "C=10\n",
        "b = (0, C)\n",
        "bounds1 =(b,b,b,b)\n",
        "optRes = optimize.minimize(fun=lambda a: QuadraticProblem(a),\n",
        "                              x0=np.ones(n), \n",
        "                              method='SLSQP', \n",
        "                              jac=lambda a: QuadraticProblemGrad(a), \n",
        "                              constraints= constraints_list, bounds = bounds1)\n",
        "alpha_resultante = optRes.x\n",
        "print(alpha_resultante)"
      ],
      "metadata": {
        "id": "8ag-N4u_lsoJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9219f64-caa2-4167-b0da-3c516f31c635"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.125 0.125 0.125 0.125]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$α_p = 0.125$  para todos os p."
      ],
      "metadata": {
        "id": "7-qx0IYwAKc4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para C=100"
      ],
      "metadata": {
        "id": "WaBJSHOBAYIY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "C=100\n",
        "b = (0, C)\n",
        "bounds1 =(b,b,b,b)\n",
        "optRes = optimize.minimize(fun=lambda a: QuadraticProblem(a),\n",
        "                              x0=np.ones(n), \n",
        "                              method='SLSQP', \n",
        "                              jac=lambda a: QuadraticProblemGrad(a), \n",
        "                              constraints= constraints_list, bounds = bounds1)\n",
        "alpha_resultante = optRes.x\n",
        "print(alpha_resultante)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uawHGvp9AaXZ",
        "outputId": "e685f74c-1a5d-4352-e253-a6c73231bfee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.125 0.125 0.125 0.125]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$α_p = 0.125$  para todos os p. Vemos então que aumentar o valor de C não altera nossa solução. Podemos tentar diminuir C para 0.1"
      ],
      "metadata": {
        "id": "bBExH8duAfTU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "C=0.1\n",
        "b = (0, C)\n",
        "bounds1 =(b,b,b,b)\n",
        "optRes = optimize.minimize(fun=lambda a: QuadraticProblem(a),\n",
        "                              x0=np.ones(n), \n",
        "                              method='SLSQP', \n",
        "                              jac=lambda a: QuadraticProblemGrad(a), \n",
        "                              constraints= constraints_list, bounds = bounds1)\n",
        "alpha_resultante = optRes.x\n",
        "print(alpha_resultante)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnzPtyZbAJoL",
        "outputId": "b2969064-dffa-42c9-987d-2e9b98c96455"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.1 0.1 0.1 0.1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vemos que o $α$ bate no teto do bound, 0.1, porém podemos ver abaixo que o valor da função é -0.24, enquanto que para os outros valores de C o valor é -0.25. Ou seja, abaixar o valor de C resultou em uma menor minimização da função, o que não é o desejado."
      ],
      "metadata": {
        "id": "ERFHzja4CNwa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optRes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FPr0nu0CFJ_",
        "outputId": "4287d321-08d2-434c-e8ea-f8173ff12cf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     fun: -0.24\n",
              "     jac: array([-0.2, -0.2, -0.2, -0.2])\n",
              " message: 'Optimization terminated successfully.'\n",
              "    nfev: 1\n",
              "     nit: 1\n",
              "    njev: 1\n",
              "  status: 0\n",
              " success: True\n",
              "       x: array([0.1, 0.1, 0.1, 0.1])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logo, nossa resposta é $α_p = 0.125$  para todos os p. "
      ],
      "metadata": {
        "id": "8BkiIEz_DwjY"
      }
    }
  ]
}